search:
  providers:
  - bing
  - naver
  - brave
  rrf:
    k: 60
    minOverlap: 1
    weights:
      bing: 1.0
      naver: 0.84
      brave: 0.7056
  cache:
    ttlSeconds: 600
  reranker:
    enabled: true
    model: onnx/cross-encoder-msmarco-MiniLM-L-6-v2.onnx
    topN: 70
    batchSize: 24
    normalizeScores: true
    scoreThreshold: 0.0
    device: cpu
    onnx:
      intraOpNumThreads: 1
      interOpNumThreads: 1
      executionProviders:
      - CPUExecutionProvider
  enabled: true
  max-concurrency: 3
budget:
  request-time-ms: 3500
naver:
  search:
    timeout-ms: 1200
    web-top-k: 12

  filters:
    domain-policy: boost
    enable-domain-filter: false
ocr:
  enabled: true
  min-confidence: 0.78
probe:
  search:
    enabled: false
  admin-token: ''
retrieval:
  vector:
    enabled: true
onnx:
  enabled: true
gate:
  citation:
    enabled: true
    min: 3
  finalSigmoid:
    enabled: true
    k: 12.0
    x0: 0.0
upstash:
  cache:
    ttl-seconds: 3600
llm:
  base-url: https://api.groq.com/openai/v1
  api-key: ${LLM_API_KEY:dummy}
  chat-model: gpt-4

  provider: groq
  # MERGED_DUP llm.base-url :: base-url: http://localhost:11434/v1   # 3090-only endpoint
  # MERGED_DUP llm.provider :: provider: local

selfask:
  enabled: false

fallback:
  enabled: false

onnx:
  enabled: true
  gpu-id: 0
  max-concurrency: 2

zsys:
  onnx:
    enabled: true
    gpu-id: 0
    max-concurrency: 2

jammini:
  guard:
    profile: PROFILE_MEMORY
  memory:
    progressive: true
