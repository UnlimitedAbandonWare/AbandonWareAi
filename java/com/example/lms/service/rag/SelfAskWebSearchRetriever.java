// src/main/java/com/example/lms/service/rag/SelfAskWebSearchRetriever.java
package com.example.lms.service.rag;

import com.example.lms.search.provider.WebSearchProvider;
import org.springframework.beans.factory.annotation.Qualifier;
import dev.langchain4j.data.message.SystemMessage;
import dev.langchain4j.data.message.UserMessage;
import dev.langchain4j.model.chat.ChatModel;
import dev.langchain4j.rag.content.Content;
import dev.langchain4j.rag.content.retriever.ContentRetriever;
import dev.langchain4j.rag.query.Query;
import lombok.RequiredArgsConstructor;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Component;
import org.springframework.util.StringUtils;
import java.util.*;
import java.util.regex.Pattern;
import jakarta.annotation.PreDestroy;
import org.slf4j.LoggerFactory;
import org.slf4j.Logger;


// SelfAskWebSearchRetriever.java


import com.example.lms.service.rag.pre.QueryContextPreprocessor;      // ğŸ†• ì „ì²˜ë¦¬ê¸° í´ë˜ìŠ¤ import
import com.example.lms.service.rag.detector.GameDomainDetector;       // + ë„ë©”ì¸ ê°ì§€
import com.example.lms.search.TypoNormalizer;                         // NEW: typo normalizer
import java.util.concurrent.*;                                        // ì¤‘ë³µ ì •ë¦¬: í•œ ë²ˆë§Œ ë‚¨ê¹€
@Component                          // â
@RequiredArgsConstructor            // â‹ ëª¨ë“  final í•„ë“œ ì£¼ì…
public class SelfAskWebSearchRetriever implements ContentRetriever {
    private static final Logger log = LoggerFactory.getLogger(SelfAskWebSearchRetriever.class);
    private final WebSearchProvider webSearchProvider;
    @Qualifier("fastChatModel")
    private final ChatModel chatModel;
        private final QueryContextPreprocessor preprocessor;
    private final GameDomainDetector domainDetector; // + GENSHIN ê°ì§€ìš©

    // Optional typo normalizer for hygiene. Injected if available.
    @Autowired(required = false)
    private TypoNormalizer typoNormalizer;

    @Autowired(required = false)
    private com.example.lms.infra.resilience.NightmareBreaker nightmareBreaker;

    /* ì„ íƒì  Tavily í´ë°±(ì¡´ì¬ ì‹œì—ë§Œ ì‚¬ìš©) */
    @Autowired(required = false)
    @Qualifier("tavilyWebSearchRetriever")
    private ContentRetriever tavily;
    /* ---------- íŠœë‹ ê°€ëŠ¥í•œ ê¸°ë³¸ê°’(í”„ë¡œí¼í‹° ì£¼ì…) ---------- */
    @Value("${selfask.max-depth:2}")                private int maxDepth;                 // Self-Ask ì¬ê·€ ê¹Šì´
    @Value("${selfask.web-top-k:8}")                private int webTopK;                  // í‚¤ì›Œë“œë‹¹ ê²€ìƒ‰ ìŠ¤ë‹ˆí« ìˆ˜
    @Value("${selfask.overall-top-k:10}")           private int overallTopK;              // ìµœì¢… ë°˜í™˜ ìƒí•œ
    @Value("${selfask.max-api-calls-per-query:8}")  private int maxApiCallsPerQuery;      // ì§ˆì˜ë‹¹ ìµœëŒ€ í˜¸ì¶œ
    @Value("${selfask.followups-per-level:2}")      private int followupsPerLevel;        // ë ˆë²¨ë³„ ì¶”ê°€ í‚¤ì›Œë“œ
    @Value("${selfask.first-hit-stop-threshold:3}") private int firstHitStopThreshold;    // 1ì°¨ ê²€ìƒ‰ì´ nê°œ ì´ìƒì´ë©´ ì¢…ë£Œ
    @Value("${selfask.timeout-seconds:12}")         private int selfAskTimeoutSec;        // ë ˆë²¨ íƒ€ì„ë°•ìŠ¤(ì´ˆ)
    @Value("${selfask.per-request-timeout-ms:5000}") private int perRequestTimeoutMs; // ê°œë³„ ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ(ms)
    @Value("${selfask.use-llm-followups:false}")     private boolean useLlmFollowups;  // í•˜ìœ„ í‚¤ì›Œë“œ LLM ì‚¬ìš© ì—¬ë¶€
    @Value("${selfask.use-llm-seeds:false}")         private boolean useLlmSeeds;      // ì‹œë“œ í‚¤ì›Œë“œ LLM ì‚¬ìš© ì—¬ë¶€
    /**
     * Search I/O executor.
     *
     * <p>Do not use {@code ForkJoinPool.commonPool} for blocking I/O (web search/HTTP).
     */
    @Autowired
    @Qualifier("searchIoExecutor")
    private ExecutorService searchExecutor;
    /** ê°„ì´ ë³µì¡ë„ ì¶”ì • â†’ Self-Ask ê¹Šì´(1..3) */
    private int estimateDepthByComplexity(String q) {
        if (!StringUtils.hasText(q)) return 1;
        int len = q.codePointCount(0, q.length());
        long spaces = q.chars().filter(ch -> ch == ' ').count();
        // vs (ëŒ€ì†Œë¬¸ì ë¬´ê´€) ë„ ë¹„êµ/ì°¨ì´ ì§ˆë¬¸ì˜ í•œ í˜•íƒœì´ë¯€ë¡œ íŒ¨í„´ì— í¬í•¨í•œë‹¤.
        boolean hasWh = q.matches(".*(?i)(ëˆ„ê°€|ì–¸ì œ|ì–´ë””|ë¬´ì—‡|ì™œ|ì–´ë–»ê²Œ|ë¹„êµ|ì°¨ì´|ì›ë¦¬|vs).*");
        int score = 0;
        if (len > 30) score++;
        if (spaces > 6) score++;
        if (hasWh) score++;
        return Math.min(3, Math.max(1, score)); // 1..3
    }
    /**
     * í¸ì˜ ìƒì„±ì(Bean ê¸°ë³¸í˜•)
     */
      /* â Lombokì´ ìƒì„±ìë¥¼ ìë™ ìƒì„±í•˜ë¯€ë¡œ
       ëª…ì‹œì  ìƒì„±ì ë¸”ë¡ì„ ì „ë¶€ ì‚­ì œí•©ë‹ˆë‹¤. */

    /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íœ´ë¦¬ìŠ¤í‹± í‚¤ì›Œë“œ ê·œì¹™ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    private static final Set<String> STOPWORDS = Set.of(
            "ê·¸ë¦¬ê³ ", "ë˜ëŠ”", "ê·¸ëŸ¬ë‚˜", "í•˜ì§€ë§Œ", "ì—ì„œ", "ìœ¼ë¡œ", "ì—ê²Œ", "ëŒ€í•œ", "ê´€ë ¨",
            "ë¬´ì—‡", "ì–´ë–»ê²Œ", "ì•Œë ¤ì¤˜", "ì •ë¦¬", "ì„¤ëª…", "í•´ì£¼ì„¸ìš”", "í•´ì£¼ì„¸ìš”."
    );

    /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì •ê·œí™” ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    private static final Pattern LEADING_TRAILING_PUNCT =
            Pattern.compile("^[\\p{Punct}\\s]+|[\\p{Punct}\\s]+$");

    /**
     * Canonicalize keyword by removing whitespace and lowercasing for duplicate detection.
     */
    private static String canonicalKeyword(String raw) {
        if (raw == null) return "";
        return raw.replaceAll("\\s+", "").toLowerCase(Locale.ROOT);
    }

    private static String normalize(String raw) {
        if (!StringUtils.hasText(raw)) return "";
        String s = LEADING_TRAILING_PUNCT.matcher(raw).replaceAll("")   // ì•ë’¤ íŠ¹ìˆ˜ë¬¸ì
                .replace("\"", "")                                      // ë”°ì˜´í‘œ
                .replace("?", "")                                       // ë¬¼ìŒí‘œ
                .replaceAll("\\s{2,}", " ")                             // ë‹¤ì¤‘ ê³µë°±
                .trim();
        // ì„ ì–¸í˜•/ì ‘ë‘ ì œê±°
        s = s.replaceFirst("^ê²€ìƒ‰ì–´\\s*:\\s*", "");
        s = s.replace("ì…ë‹ˆë‹¤", "");
        return s;
    }

    /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ContentRetriever êµ¬í˜„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    @Override
    public List<Content> retrieve(Query query) {
        // ì…ë ¥ ê²€ì¦


        String qText = (query != null) ? query.text() : null;
        java.util.Map<String, Object> meta = toMetaMap(query);
        meta.putIfAbsent("purpose", "WEB_SEARCH");
        // Apply typo normalization if configured
        if (typoNormalizer != null && qText != null) {
            qText = typoNormalizer.normalize(qText);
        }
        // â‘  Guardrail: ì˜¤íƒ€ êµì •/ê¸ˆì¹™ì–´/ì¤‘ë³µ ì •ë¦¬ (ì¤‘ë³µ í˜¸ì¶œ ì œê±° + NPE ê°€ë“œ)
        qText = (preprocessor != null) ? preprocessor.enrich(qText, meta) : qText;
        if (!StringUtils.hasText(qText)) {
            log.debug("[SelfAsk] empty query -> []");
            return List.of();
        }

        int reqWebTopK = metaInt(meta, "webTopK", this.webTopK);
        long webBudgetMs = metaLong(meta, "webBudgetMs", -1L);
        boolean allowWeb = metaBool(meta, "allowWeb", true);
        if (!allowWeb) {
            return java.util.List.of();
        }
        boolean enableSelfAskHint = metaBool(meta, "enableSelfAsk", true);
        boolean nightmareMode = metaBool(meta, "nightmareMode", false);
        boolean auxLlmDown = metaBool(meta, "auxLlmDown", false);

        int reqPerRequestTimeoutMs = this.perRequestTimeoutMs;
        int reqSelfAskTimeoutSec = this.selfAskTimeoutSec;
        if (webBudgetMs > 0) {
            reqPerRequestTimeoutMs = (int) Math.min((long) reqPerRequestTimeoutMs, Math.max(300L, webBudgetMs));
            reqSelfAskTimeoutSec = (int) Math.min((long) reqSelfAskTimeoutSec, Math.max(1L, (webBudgetMs + 999L) / 1000L));
        }

        /* 1) ë¹ ë¥¸ 1ì°¨ ê²€ìƒ‰ */
        java.util.List<String> firstSnippets = safeSearch(qText, reqWebTopK);

        // ì§ˆì˜ ë³µì¡ë„ ê°„ë‹¨ íŒì •
        boolean enableSelfAsk = qText.length() > 25
                || qText.chars().filter(ch -> ch == ' ').count() > 3
                // 'ë¹„êµ', 'ì°¨ì´' ë˜ëŠ” ' vs 'ê°€ í¬í•¨ë˜ë©´ Self-Askê°€ í•„ìš”í•˜ë‹¤.
                || qText.contains("ë¹„êµ")
                || qText.contains("ì°¨ì´")
                || qText.toLowerCase(Locale.ROOT).contains(" vs ");
        if (!enableSelfAskHint || nightmareMode) {
            enableSelfAsk = false;
        }
        final boolean useLlmSeedsHere = this.useLlmSeeds && enableSelfAskHint && !nightmareMode && !auxLlmDown;
        final boolean useLlmFollowupsHere = this.useLlmFollowups && enableSelfAskHint && !nightmareMode && !auxLlmDown;

        // ì§ˆì˜ ë³µì¡ë„ ê¸°ë°˜ ë™ì  ê¹Šì´(1..maxDepth)
        final int depthLimit = Math.max(1, Math.min(maxDepth, estimateDepthByComplexity(qText)));

        /* 1-B) Self-Ask ì¡°ê¸° ì¢…ë£Œ ê²°ì • (í’ˆì§ˆ í‰ê°€ëŠ” LLM í‚¤ì›Œë“œ í™•ì¥ì—ì„œ ìˆ˜í–‰) */
        if (!enableSelfAsk) {
            if (firstSnippets.isEmpty()) return List.of();
            // ë‹¨ìˆœ ì§ˆì˜ë©´ì„œ 1ì°¨ì—ì„œ ì¶©ë¶„íˆ ë§ì´ ë§ìœ¼ë©´(=ì¡°ê¸° ì¢…ë£Œ)
            if (firstSnippets.size() >= firstHitStopThreshold) {
                return firstSnippets.stream().limit(overallTopK).map(Content::from).toList();
            }
            // ì•„ë‹ˆë©´ ì–•ê²Œ í•œ ë²ˆë§Œ í™•ì¥
            if (depthLimit <= 1) {
                return firstSnippets.stream().limit(overallTopK).map(Content::from).toList();
            }
        }

        // 2) íœ´ë¦¬ìŠ¤í‹± í‚¤ì›Œë“œ ì‹œë“œ êµ¬ì„± â†’ BFS í™•ì¥
        java.util.List<String> seeds = new java.util.ArrayList<>(basicKeywords(qText, useLlmSeedsHere));

        // Seed queue with canonical uniqueness to avoid duplicate/synonym searches
        Deque<String> queue = new ArrayDeque<>();
        Set<String> visitedCanon = new HashSet<>();
        for (String s : seeds) {
            String norm = normalize(s);
            if (StringUtils.hasText(norm)) {
                String canon = canonicalKeyword(norm);
                if (visitedCanon.add(canon)) {
                    queue.add(norm);
                }
            }
        }


        // 3) BFS(Self-Ask) + ë„¤ì´ë²„ ê²€ìƒ‰
        LinkedHashSet<String> snippets = new LinkedHashSet<>(firstSnippets);
        int depth = 0;
        SearchBudget budget = new SearchBudget(maxApiCallsPerQuery); // âœ… í˜¸ì¶œ ìƒí•œ ì œì–´

        while (!queue.isEmpty() && snippets.size() < overallTopK && depth < depthLimit) {
            int levelSize = queue.size();
            List<String> currentKeywords = new ArrayList<>();
            while (levelSize-- > 0) {
                String kw = normalize(queue.poll());
                if (StringUtils.hasText(kw)) currentKeywords.add(kw);
            }


            // í•´ë‹¹ depthì˜ í‚¤ì›Œë“œë“¤ì„ ë³‘ë ¬ ê²€ìƒ‰ (ìƒí•œ ì ìš©)
                List<Future<List<String>>> futures = new ArrayList<>();
            for (String kw : currentKeywords) {
                if (!budget.tryConsume()) break; // âœ… ìƒí•œ
                log.debug("[SelfAsk][d{}] ê²€ìƒ‰ì–´: {}", depth, kw);
                Future<java.util.List<String>> f = searchExecutor.submit(() -> safeSearch(kw, reqWebTopK));
                futures.add(f);

            }

            // Level-wide budget for this depth.
            // Important: we do NOT rely on CompletableFuture.orTimeout(), because it only times out the
            // future result and may leave the underlying work running ("zombie" tasks).
            final long levelDeadlineMs = System.currentTimeMillis() + java.util.concurrent.TimeUnit.SECONDS.toMillis(reqSelfAskTimeoutSec);

            // ê²°ê³¼ ë³‘í•© ë° ë‹¤ìŒ ë ˆë²¨ í‚¤ì›Œë“œ ìƒì„±
            for (int i = 0; i < futures.size(); i++) {
                String kw = i < currentKeywords.size() ? currentKeywords.get(i) : "";
                List<String> results = getWithHardTimeout(
                        futures.get(i),
                        Math.min(reqPerRequestTimeoutMs, Math.max(0L, levelDeadlineMs - System.currentTimeMillis())),
                        kw
                );
                results.forEach(snippets::add);

                if (depth + 1 <= maxDepth && snippets.size() < overallTopK) {
                    int used = 0;
                    // LLM í˜¸ì¶œ ìµœì†Œí™”: ê¸°ë³¸ì€ íœ´ë¦¬ìŠ¤í‹±, í•„ìš” ì‹œì—ë§Œ LLM
                    java.util.List<String> children = useLlmFollowupsHere
                            ? followUpKeywords(kw)
                            : heuristicFollowups(kw);
                    for (String child : children) {
                        if (used >= followupsPerLevel) break;  // per-level ì œí•œ
                        String norm = normalize(child);
                        String canon = canonicalKeyword(norm);
                        if (StringUtils.hasText(norm) && visitedCanon.add(canon)) {
                            queue.add(norm);
                            used++;
                        }
                    }
                }
            }

            // Cancel any straggling tasks once this depth budget is exhausted.
            for (Future<List<String>> f : futures) {
                if (f != null && !f.isDone()) {
                    // Interrupt Hygiene: never interrupt pooled workers (cancel(false) only).
                    f.cancel(false);
                }
            }
            depth++;
        }

        // 3-B) ê²°ê³¼ ë¶€ì¡± ì‹œ Tavilyë¡œ ë³´ê°•
        if (snippets.size() < overallTopK && tavily != null) {
            try {
                int need = Math.max(0, overallTopK - snippets.size());
                // [HARDENING] Always propagate existing query metadata (e.g. session sid) when
                // constructing new Query objects for the Tavily fallback.  This ensures that
                // downstream retrievers enforce per-session isolation and do not pollute
                // transient or public namespaces.  When the original query has no metadata
                // attached, the builder will accept a null and Tavily will treat it as
                // __PRIVATE__ internally.  Avoid the deprecated Query.from API.
                // [HARDENING] use builder API to propagate metadata and avoid deprecated Query.from
                Query fallbackQuery = dev.langchain4j.rag.query.Query.builder()
                        .text(qText)
                        .metadata((query != null ? query.metadata() : null))
                        .build();
                tavily.retrieve(fallbackQuery).stream()
                        .map(Content::toString)
                        .filter(StringUtils::hasText)
                        .limit(need)
                        .forEach(snippets::add);
            } catch (Exception e) {
                log.debug("[SelfAsk] Tavily fallback skipped: {}", e.toString());
            }
        }
// 4) Content ë³€í™˜(ë¹„ì–´ìˆì„ ê²½ìš° ì•ˆì „ í´ë°±)
        if (snippets.isEmpty()) {
            if (!firstSnippets.isEmpty()) {
                return firstSnippets.stream()
                        .limit(Math.max(1, Math.min(overallTopK, reqWebTopK)))
                        .map(Content::from)
                        .toList();
            }
            // No snippets found at all. Return an empty list instead of a placeholder to avoid polluting the vector store.
            return java.util.List.of();
        }
        return snippets.stream()
                .limit(overallTopK)
                .map(Content::from)
                .toList();
    }



    // ---- per-request metadata helpers (OrchestrationHints bridge) ----
    @SuppressWarnings("unchecked")
    private static java.util.Map<String, Object> toMetaMap(Query query) {
        if (query == null || query.metadata() == null) return java.util.Collections.emptyMap();
        Object meta = query.metadata();
        if (meta instanceof java.util.Map<?, ?> raw) {
            java.util.Map<String, Object> out = new java.util.HashMap<>();
            for (java.util.Map.Entry<?, ?> e : raw.entrySet()) {
                if (e.getKey() != null) out.put(String.valueOf(e.getKey()), e.getValue());
            }
            return out;
        }
        try {
            java.lang.reflect.Method m = meta.getClass().getMethod("asMap");
            Object v = m.invoke(meta);
            if (v instanceof java.util.Map<?, ?> m2) {
                java.util.Map<String, Object> out = new java.util.HashMap<>();
                for (java.util.Map.Entry<?, ?> e : m2.entrySet()) {
                    if (e.getKey() != null) out.put(String.valueOf(e.getKey()), e.getValue());
                }
                return out;
            }
        } catch (NoSuchMethodException ignore) {
            try {
                java.lang.reflect.Method m = meta.getClass().getMethod("map");
                Object v = m.invoke(meta);
                if (v instanceof java.util.Map<?, ?> m2) {
                    java.util.Map<String, Object> out = new java.util.HashMap<>();
                    for (java.util.Map.Entry<?, ?> e : m2.entrySet()) {
                        if (e.getKey() != null) out.put(String.valueOf(e.getKey()), e.getValue());
                    }
                    return out;
                }
            } catch (Exception ignore2) {
                return java.util.Collections.emptyMap();
            }
        } catch (Exception ignore) {
            return java.util.Collections.emptyMap();
        }
        return java.util.Collections.emptyMap();
    }

    private static int metaInt(java.util.Map<String, Object> meta, String key, int def) {
        if (meta == null) return def;
        Object v = meta.get(key);
        if (v instanceof Number n) return n.intValue();
        if (v instanceof String s) {
            try { return Integer.parseInt(s.trim()); } catch (Exception ignore) {}
        }
        return def;
    }

    private static long metaLong(java.util.Map<String, Object> meta, String key, long def) {
        if (meta == null) return def;
        Object v = meta.get(key);
        if (v instanceof Number n) return n.longValue();
        if (v instanceof String s) {
            try { return Long.parseLong(s.trim()); } catch (Exception ignore) {}
        }
        return def;
    }

    private static boolean metaBool(java.util.Map<String, Object> meta, String key, boolean def) {
        if (meta == null) return def;
        Object v = meta.get(key);
        if (v instanceof Boolean b) return b;
        if (v instanceof Number n) return n.intValue() != 0;
        if (v instanceof String s) {
            String t = s.trim().toLowerCase();
            if (t.equals("true") || t.equals("1") || t.equals("yes")) return true;
            if (t.equals("false") || t.equals("0") || t.equals("no")) return false;
        }
        return def;
    }
    // Executor lifecycle is managed by Spring (SearchExecutorConfig.searchIoExecutor).

    /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‚¤ì›Œë“œ Helper (íœ´ë¦¬ìŠ¤í‹±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    /** ì–•ì€ 1~3ê°œ ì‹œë“œ í‚¤ì›Œë“œ */
    /**
     * LLMÂ í•œÂ ë²ˆìœ¼ë¡œ 1~3ê°œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ
     */
    private List<String> basicKeywords(String question, boolean allowLlm) {
        if (!StringUtils.hasText(question)) return List.of();
        if (!allowLlm) return heuristicSeeds(question);

        String prompt = SEARCH_PROMPT.formatted(question.trim());
        String reply = "";
        try {
            if (nightmareBreaker != null) {
                reply = nightmareBreaker.execute(
                        com.example.lms.infra.resilience.NightmareKeys.SELFASK_SEED,
                        prompt,
                        () -> chatModel.chat(List.of(
                                SystemMessage.from("ë‹¹ì‹ ì€ ìµœê³ ì˜ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
                                UserMessage.from(prompt)
                        )).aiMessage().text(),
                        com.example.lms.infra.resilience.FriendShieldPatternDetector::looksLikeSilentFailure,
                        () -> ""
                );
            } else {
                reply = chatModel.chat(List.of(
                        SystemMessage.from("ë‹¹ì‹ ì€ ìµœê³ ì˜ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
                        UserMessage.from(prompt)
                )).aiMessage().text();
            }
        } catch (Exception e) {
            log.warn("LLM keyword generation failed", e);
        }

        List<String> out = splitLines(reply).stream().limit(3).toList();
        if (out == null || out.isEmpty()) return heuristicSeeds(question);
        return out;
    }

    private List<String> heuristicSeeds(String question) {
        if (!StringUtils.hasText(question)) return List.of();
        String cleaned = question.replaceAll("[\\p{Punct}]+", " ").trim();
        if (!StringUtils.hasText(cleaned)) {
            return List.of(question.trim());
        }

        java.util.LinkedHashSet<String> uniq = new java.util.LinkedHashSet<>();
        for (String t : cleaned.split("\\s+")) {
            String norm = normalize(t);
            if (!StringUtils.hasText(norm)) continue;
            String canon = canonicalKeyword(norm);
            if (!StringUtils.hasText(canon)) continue;
            uniq.add(norm);
            if (uniq.size() >= 3) break;
        }
        if (uniq.isEmpty()) return List.of(question.trim());
        return uniq.stream().limit(3).toList();
    }

    /**
     * Self-Ask í•˜ìœ„ í‚¤ì›Œë“œë¥¼ LLMìœ¼ë¡œ 1~2ê°œ ìƒì„±
     */
    private List<String> followUpKeywords(String parent) {
        if (!StringUtils.hasText(parent)) return List.of();
        String prompt = FOLLOWUP_PROMPT.formatted(parent.trim());
        String reply = "";
        try {
            if (nightmareBreaker != null) {
                reply = nightmareBreaker.execute(
                        com.example.lms.infra.resilience.NightmareKeys.SELFASK_FOLLOWUP,
                        prompt,
                        () -> chatModel.chat(List.of(
                                SystemMessage.from("ê²€ìƒ‰ì–´ë¥¼ ë” êµ¬ì²´í™”í•˜ì„¸ìš”."),
                                UserMessage.from(prompt)
                        )).aiMessage().text(),
                        com.example.lms.infra.resilience.FriendShieldPatternDetector::looksLikeSilentFailure,
                        () -> ""
                );
            } else {
                reply = chatModel.chat(List.of(
                        SystemMessage.from("ê²€ìƒ‰ì–´ë¥¼ ë” êµ¬ì²´í™”í•˜ì„¸ìš”."),
                        UserMessage.from(prompt)
                )).aiMessage().text();
            }
        } catch (Exception e) {
            log.warn("LLM follow-up generation failed", e);
        }

        List<String> out = splitLines(reply).stream().limit(Math.max(1, followupsPerLevel)).toList();
        if (out == null || out.isEmpty()) return heuristicFollowups(parent);
        return out;
    }

    /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM í”„ë¡¬í”„íŠ¸ ìƒìˆ˜ ë° ê²€ìƒ‰ ì˜ˆì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

    private static final String SEARCH_PROMPT = """
            ë‹¹ì‹ ì€ ê²€ìƒ‰ì–´ ìƒì„±ê¸°ì…ë‹ˆë‹¤.
            ì‚¬ìš©ì ì§ˆë¬¸ì„ ê°€ì¥ íš¨ê³¼ì ìœ¼ë¡œ ì°¾ì„ ìˆ˜ ìˆëŠ” **ì§§ì€ í‚¤ì›Œë“œí˜• ì§ˆì˜** 1~3ê°œë¥¼ ì œì‹œí•˜ì„¸ìš”.
            - ì„¤ëª…ì´ë‚˜ ì ‘ë‘ì‚¬ëŠ” ê¸ˆì§€í•˜ê³ , í•œ ì¤„ì— ê²€ìƒ‰ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
            ì§ˆë¬¸: %s
            """;

    private static final String FOLLOWUP_PROMPT = """
            "%s" ê²€ìƒ‰ì–´ê°€ ê´‘ë²”ìœ„í•©ë‹ˆë‹¤.
            ë” êµ¬ì²´ì ì´ê³  ì •ë³´ì„±ì„ ë†’ì¼ **í‚¤ì›Œë“œí˜• ì§ˆì˜** 1~2ê°œë§Œ í•œêµ­ì–´ë¡œ ì œì•ˆí•˜ì„¸ìš”.
            (í•œ ì¤„ì— í•˜ë‚˜, ì„¤ëª… ê¸ˆì§€)
            """;

    /**
     * ì§ˆì˜ë³„ API í˜¸ì¶œ ì˜ˆì‚° ê´€ë¦¬
     */
    private static final class SearchBudget {
        private int left;

        SearchBudget(int max) {
            this.left = Math.max(0, max);
        }

        boolean tryConsume() {
            return left-- > 0;
        }

        int remaining() {
            return Math.max(0, left);
        }
    }

    /**
     * Hard timeout: on timeout, actively cancel the running task.
     */
    private List<String> getWithHardTimeout(Future<List<String>> future, long timeoutMs, String keyword) {
        if (future == null) {
            return List.of();
        }
        if (timeoutMs <= 0) {
            // Best-effort cancel without interrupt to avoid cancellation toxicity.
            future.cancel(false);
            return List.of();
        }
        try {
            List<String> v = future.get(timeoutMs, TimeUnit.MILLISECONDS);
            return (v != null) ? v : List.of();
        } catch (TimeoutException te) {
            // Best-effort cancel without interrupt to avoid poisoning pooled workers.
            future.cancel(false);
            log.debug("[SelfAsk] hard timeout ({}ms) keyword={}", timeoutMs, keyword);
            return List.of();
        } catch (InterruptedException ie) {
            // Interrupt Hygiene: consume interrupt flag (parry) and fail-soft.
            Thread.interrupted();
            future.cancel(false);
            log.debug("[SelfAsk] interrupted while waiting keyword={} (interrupt consumed)", keyword);
            return List.of();
        } catch (Exception e) {
            future.cancel(false);
            log.debug("[SelfAsk] keyword search failed: {} -> {}", keyword, e.toString());
            return List.of();
        }
    }

    private List<String> safeSearch(String q, int k) {
        try {
            if (!StringUtils.hasText(q)) return List.of();
            return webSearchProvider.search(q, k);
        } catch (Exception e) {
            log.warn("ì´ˆê¸° ê²€ìƒ‰ ì‹¤íŒ¨: {}", q, e);
            return Collections.emptyList();
        }
    }
    /** LLM í˜¸ì¶œ ì—†ì´ ê°„ë‹¨ í™•ì¥(ìµœëŒ€ followupsPerLevelê°œ) - ë„ë©”ì¸ ë¯¼ê° */
    private List<String> heuristicFollowups(String parent) {
        if (!StringUtils.hasText(parent)) return List.of();
        boolean isGenshin = (domainDetector != null)
                && "GENSHIN".equalsIgnoreCase(domainDetector.detect(parent));
        List<String> cands = isGenshin
                ? List.of(parent + " íŒŒí‹° ì¡°í•©", parent + " ì‹œë„ˆì§€", parent + " ìƒì„±", parent + " ì¶”ì²œ íŒŒí‹°")
                : List.of(parent + " ê°œìš”", parent + " í•µì‹¬ í¬ì¸íŠ¸");
        return cands.stream()
                .limit(Math.max(1, followupsPerLevel))
                .toList();
    }

    /**
     * ë¡œì»¬ íœ´ë¦¬ìŠ¤í‹±: ì‹¤ì‹œê°„ íŒ¨ì¹˜/ê³µì§€ ì§ˆì˜ ì—¬ë¶€
     */


    private static List<String> splitLines(String raw) {
        if (!StringUtils.hasText(raw)) return List.of();
        return Arrays.stream(raw.split("\\R+"))
                .map(String::trim)
                .filter(s -> !s.isBlank())
                .distinct()
                .toList();
    }

    private List<String> rephrase(String q) {
        if (q == null || q.isBlank()) return List.of();
        // í•„ìš”í•˜ë©´ ë” ë˜‘ë˜‘í•˜ê²Œ í™•ì¥
        return List.of(q, q + " í›„ê¸°", q + " ì •ë¦¬", q + " ìš”ì•½");
    }




    // [HARDENING] ensure SID metadata is present on every query
    private dev.langchain4j.rag.query.Query ensureSidMetadata(dev.langchain4j.rag.query.Query original, String sessionKey) {
        var md = (original.metadata() != null)
                ? original.metadata()
                : dev.langchain4j.data.document.Metadata.from(
                java.util.Map.of(com.example.lms.service.rag.LangChainRAGService.META_SID, sessionKey));
        try {
            return dev.langchain4j.rag.query.Query.builder()
                    .text(original.text())
                    .metadata(md)
                    .build();
        } catch (Throwable t) {
            try {
                // Fallback: ì¼ë¶€ í™˜ê²½ì—ì„œë§Œ ì¡´ì¬í•  ìˆ˜ ìˆëŠ” ìƒì„±ì(ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜)
                var ctor = dev.langchain4j.rag.query.Query.class
                        .getDeclaredConstructor(String.class, dev.langchain4j.data.document.Metadata.class);
                ctor.setAccessible(true);
                return ctor.newInstance(original.text(), md);
            } catch (Throwable t2) {
                return original;
            }
        }
    }

}