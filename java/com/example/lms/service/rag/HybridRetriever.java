package com.example.lms.service.rag;

import com.example.rag.fusion.WeightedRRF;
import com.example.retrieval.KAllocator;
import com.example.moe.GateVector;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import com.example.lms.service.rag.fusion.ReciprocalRankFuser;
import com.example.lms.service.rag.handler.RetrievalHandler;
import com.example.lms.search.QueryHygieneFilter;
import com.example.lms.util.SoftmaxUtil;
import org.springframework.beans.factory.annotation.Autowired;
import dev.langchain4j.data.segment.TextSegment;
import dev.langchain4j.model.embedding.EmbeddingModel;
import dev.langchain4j.rag.content.Content;
import dev.langchain4j.rag.content.retriever.ContentRetriever;
import dev.langchain4j.rag.query.Query;
import com.example.lms.service.rag.QueryUtils;
import dev.langchain4j.store.embedding.EmbeddingStore;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Component;
import lombok.RequiredArgsConstructor;
import com.example.lms.service.rag.rerank.LightWeightRanker;
import com.example.lms.transform.QueryTransformer;
import com.example.lms.prompt.PromptContext;
import java.lang.reflect.Method;
import java.util.*;
import java.util.stream.Collectors;
import java.util.concurrent.ForkJoinPool;
import com.example.lms.service.rag.auth.AuthorityScorer;
import com.example.lms.util.MLCalibrationUtil;
import com.example.lms.service.scoring.AdaptiveScoringService;
import com.example.lms.service.knowledge.KnowledgeBaseService;
import com.example.lms.learning.NeuralPathFormationService;
import com.example.lms.service.rag.rerank.RerankGate;
import com.example.lms.service.VectorMetaKeys;

import dev.langchain4j.rag.query.Metadata; // [HARDENING] 1.0.x Query ë©”íƒ€ íƒ€ì…
import java.util.Map; // [HARDENING]
// imports
import com.example.lms.service.rag.rerank.ElementConstraintScorer; //  ì‹ ê·œ ì¬ë­ì»¤

import com.example.lms.service.config.HyperparameterService; // â˜… NEW
import com.example.lms.search.TraceStore;
import com.example.lms.infra.resilience.NightmareBreaker;
import com.example.lms.infra.resilience.NightmareKeys;
import org.springframework.beans.factory.annotation.Qualifier; // - FIX: ë‹¤ì¤‘ ë¹ˆ ëª¨í˜¸ì„± í•´ê²°ìš© @Qualifier
import jakarta.annotation.PostConstruct; // + ê°œì„ : í”„ë¡œí¼í‹° ê¸°ë°˜ ë°±ì—”ë“œ ì„ íƒ ì§€ì›

@Component("vectorRetriever")
@RequiredArgsConstructor
public class HybridRetriever implements ContentRetriever {

    @Value("${selfask.enabled:true}")
    private boolean selfAskEnabled;

    private static final Logger log = LoggerFactory.getLogger(HybridRetriever.class);

    // fields (ë‹¤ë¥¸ final í•„ë“œë“¤ê³¼ ê°™ì€ ìœ„ì¹˜)
    private final LightWeightRanker lightWeightRanker;
    // Gate controlling invocation of the expensive cross-encoder reranker.
    private final com.example.lms.service.rag.rerank.RerankGate rerankGate;
    private final AuthorityScorer authorityScorer;
    private static final double GAME_SIM_THRESHOLD = 0.3;

    // ë©”íƒ€í‚¤ (í•„ìš” ì‹œ Query.metadataì— ì‹¤ì–´ ì „ë‹¬)
    private static final String META_ALLOWED_DOMAINS = "allowedDomains"; // List<String>
    private static final String META_MAX_PARALLEL = "maxParallel"; // Integer
    private static final String META_DEDUPE_KEY = "dedupeKey"; // "text" | "url" | "hash"
    private static final String META_OFFICIAL_DOMAINS = "officialDomains"; // List<String>

    @Value("${rag.search.top-k:5}")
    private int topK;

    // ì²´ì¸ & ìœµí•©ê¸°
    private final RetrievalHandler handlerChain;
    private final ReciprocalRankFuser fuser;
    // Optional weighted RRF fuser. When present and the fusionMode is set
    // appropriately (e.g. "weighted-rrf"), the hybrid retriever will use it
    // instead of the standard RRF fuser. The WeightedReciprocalRankFuser
    // supports per-source weights tuned at runtime via the HyperparameterService.
    @Autowired(required = false)
    private com.example.lms.service.rag.fusion.WeightedReciprocalRankFuser weightedFuser;
    private final AnswerQualityEvaluator qualityEvaluator;
    private final SelfAskPlanner selfAskPlanner;
    private final RelevanceScoringService relevanceScoringService;
    private final HyperparameterService hp; // â˜… NEW: ë™ì  ê°€ì¤‘ì¹˜ ë¡œë”
    private final ElementConstraintScorer elementConstraintScorer; // â˜… NEW: ì›ì†Œ ì œì•½ ì¬ë­ì»¤
    private final QueryTransformer queryTransformer; // â˜… NEW: ìƒíƒœ ê¸°ë°˜ ì§ˆì˜ ìƒì„±
    private final AdaptiveScoringService scoring;
    private final KnowledgeBaseService kb;
    // Path formation service used to reinforce high-consistency entity pairs.
    private final NeuralPathFormationService pathFormation;

    /**
     * Optional Redis-backed cooldown service used to guard expensive
     * operations such as cross-encoder reranking. When configured this
     * service attempts to acquire a short-lived lock prior to invoking
     * the reranker. If the lock is unavailable the reranking step is
     * skipped, allowing the system to fall back to the first pass
     * ranking. The field may be null when no Redis instance is
     * available or when cooldown gating is disabled.
     */
    @Autowired(required = false)
    private com.example.lms.service.redis.RedisCooldownService cooldownService;

    // ğŸ”´ NEW: êµì°¨ì—”ì½”ë” ê¸°ë°˜ ì¬ì •ë ¬(ì—†ìœ¼ë©´ ìŠ¤í‚µ)
    @Autowired(required = false)
    @Qualifier("noopCrossEncoderReranker") // - FIX: ë¹ˆ 3ê°œ(onnx/noop/embedding) ì¶©ëŒ â†’ ê¸°ë³¸ noopë¡œ ëª…ì‹œ
    private com.example.lms.service.rag.rerank.CrossEncoderReranker crossEncoderReranker;

    @Autowired(required = false)
    private Map<String, com.example.lms.service.rag.rerank.CrossEncoderReranker> rerankers = java.util.Collections
            .emptyMap(); // + ê°œì„ : ëŸ°íƒ€ì„ì— ë°±ì—”ë“œ ìŠ¤ìœ„ì¹­ ê°€ëŠ¥

    @Autowired(required = false)
    private NightmareBreaker nightmareBreaker;

    @Value("${abandonware.reranker.backend:noop}")
    private String rerankerBackend; // + ê°œì„ : í”„ë¡œí¼í‹°ë¡œ onnx/embedding/noop ì„ íƒ

    // ë¦¬íŠ¸ë¦¬ë²„ë“¤
    private final SelfAskWebSearchRetriever selfAskRetriever;
    private final AnalyzeWebSearchRetriever analyzeRetriever;
    private final WebSearchRetriever webSearchRetriever;
    private final QueryComplexityGate gate;

    // (ì˜µì…˜) íƒ€ì‚¬ ê²€ìƒ‰ê¸° - ìˆìœ¼ë©´ ë¶€ì¡±ë¶„ ë³´ê°•ì— ì‚¬ìš©
    @Autowired(required = false)
    @org.springframework.beans.factory.annotation.Qualifier("tavilyWebSearchRetriever")
    private ContentRetriever tavilyWebSearchRetriever;
    // RAG/ì„ë² ë”©
    private final LangChainRAGService ragService;
    private final EmbeddingModel embeddingModel;
    private final EmbeddingStore<TextSegment> gameEmbeddingStore;

    // ---------------------------------------------------------------------
    // Domain detector for selecting the appropriate Pinecone index. When the
    // domain is GENERAL a dedicated general index may be used (configured via
    // pinecone.index.general). When null the default index (pinecone.index.name)
    // will be used for all domains.
    private final com.example.lms.service.rag.detector.GameDomainDetector domainDetector;

    /**
     * Name of the Pinecone index used for GENERAL domain queries. When this
     * property is blank or undefined the default pineconeIndexName will be
     * used instead. Configure via application.yml: pinecone.index.general.
     */
    @org.springframework.beans.factory.annotation.Value("${pinecone.index.general:}")
    private String pineconeIndexGeneral;

    /**
     * Choose the appropriate index name based on the detected domain. If
     * the domain is GENERAL and a general index has been configured via
     * pinecone.index.general then that index is returned; otherwise the
     * default pineconeIndexName is used.
     *
     * @param domain the detected domain (case-insensitive)
     * @
     * return the name of the pinecone index to query
     */
    private String chooseIndex(String domain) {
        if (domain != null && "GENERAL".equalsIgnoreCase(domain)) {
            if (pineconeIndexGeneral != null && !pineconeIndexGeneral.isBlank()) {
                return pineconeIndexGeneral;
            }
        }
        return pineconeIndexName;
    }

    @Value("${pinecone.index.name}")
    private String pineconeIndexName;

    @Value("${hybrid.debug.sequential:false}")
    private boolean debugSequential;
    @Value("${hybrid.progressive.quality-min-docs:1}")
    private int qualityMinDocs;
    @Value("${hybrid.progressive.quality-min-score:0.45}")
    private double qualityMinScore;
    @Value("${hybrid.max-parallel:3}")
    private int maxParallel;

    @Value("${hybrid.min-relatedness:0.01}") // ê´€ë ¨ë„ í•„í„° ì»·ì˜¤í”„
    private double minRelatedness;
    // â˜… ìœµí•© ëª¨ë“œ: rrf(ê¸°ë³¸) | softmax
    @Value("${retrieval.fusion.mode:rrf}")
    private String fusionMode;
    // â˜… softmax ìœµí•© ì˜¨ë„
    @Value("${retrieval.fusion.softmax.temperature:1.0}")
    private double fusionTemperature;

    /**
     * Calibration mode for softmax fusion. Supported values are
     * {@code minmax}, {@code isotonic} and {@code none}. When set to
     * {@code none} or any unsupported value the softmax fusion pathway is
     * disabled and the system will fall back to RRF. This value is
     * configurable via application.yml (retrieval.fusion.softmax.calibration).
     */
    @Value("${retrieval.fusion.softmax.calibration:none}")
    private String softmaxCalibration;

    /**
     * The number of candidates that will be sent to the cross-encoder reranker.
     * This value is used by the rerank gate to decide whether or not to invoke
     * the expensive cross-encoder reordering step. When the first pass
     * candidate set contains fewer than this number of elements the reranker
     * is skipped. Defaults to 12 if unspecified.
     * <p>
     * Config key drift-safe lookup:
     * <ul>
     * <li>{@code ranking.rerank.ce.topK} (legacy)</li>
     * <li>{@code rerank.ce.topK} (canonical)</li>
     * </ul>
     */
    @Value("${ranking.rerank.ce.topK:${rerank.ce.topK:12}}")
    private int rerankCeTopK;
    @Value("${retrieval.rank.use-ml-correction:true}")
    private boolean useMlCorrection; // â˜… NEW: ML ë³´ì • ì˜¨/ì˜¤í”„

    /** ê²€ìƒ‰ ì¼ê´€ì„± â†’ ì•”ë¬µ ê°•í™” ì„ê³„ì¹˜ */
    @Value("${retrieval.consistency.threshold:0.8}")
    private double consistencyThreshold;

    @PostConstruct
    private void selectRerankerByProperty() {
        // application.yml ì˜ abandonware.reranker.backend ê°’ì— ë”°ë¼ ë°±ì—”ë“œ ìë™ ì„ íƒ
        try {
            if (rerankerBackend == null || rerankerBackend.isBlank()) {
                return;
            }

            String backend = rerankerBackend.trim().toLowerCase();
            String key;
            switch (backend) {
                case "onnx-runtime":
                case "onnx":
                    key = "onnxCrossEncoderReranker";
                    break;
                case "embedding-model":
                case "embedding":
                    key = "embeddingCrossEncoderReranker";
                    break;
                case "noop":
                case "none":
                case "disabled":
                    key = "noopCrossEncoderReranker";
                    break;
                default:
                    // legacy pattern: "<backend>CrossEncoderReranker"
                    key = backend + "CrossEncoderReranker";
                    break;
            }

            com.example.lms.service.rag.rerank.CrossEncoderReranker chosen = rerankers.get(key);

            // Backward compatibility: if someone still registers "crossEncoderReranker"
            // only.
            if (chosen == null && key.endsWith("CrossEncoderReranker")) {
                chosen = rerankers.get("crossEncoderReranker");
            }

            if (chosen != null) {
                this.crossEncoderReranker = chosen;
                log.info("[Hybrid] CrossEncoderReranker set via property backend='{}' bean='{}'", rerankerBackend, key);
            } else if (!rerankers.isEmpty()) {
                // last-resort: pick any available implementation to keep the pipeline alive
                com.example.lms.service.rag.rerank.CrossEncoderReranker fallback = rerankers.values().iterator().next();
                this.crossEncoderReranker = fallback;
                log.warn("[Hybrid] Reranker bean '{}' not found for backend='{}' â†’ using '{}'",
                        key, rerankerBackend, fallback.getClass().getSimpleName());
            } else {
                log.info("[Hybrid] No reranker beans registered; keeping injected default: {}",
                        (crossEncoderReranker != null ? crossEncoderReranker.getClass().getSimpleName() : "none"));
            }
        } catch (Exception ignore) {
            // ì•ˆì „: ì„ íƒ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì£¼ì… ìœ ì§€
        }
    }

    /**
     * Resolve the CrossEncoderReranker for the current request.
     *
     * Supports plan/meta overrides via:
     * - rerank.backend | rerank_backend | rerankBackend (string)
     * - onnx.enabled (bool) to disallow ONNX at plan level
     *
     * Also supports an "auto" backend that selects ONNX when available & allowed,
     * otherwise falls back to the embedding reranker.
     */
    private com.example.lms.service.rag.rerank.CrossEncoderReranker resolveCrossEncoderReranker(
            java.util.Map<String, Object> metaMap,
            String backendOverride,
            Boolean onnxEnabledOverride,
            boolean crossEncoderEnabled) {

        if (rerankers == null || rerankers.isEmpty()) {
            return new com.example.lms.service.rag.rerank.NoopCrossEncoderReranker();
        }

        String backend = backendOverride;
        if (backend == null || backend.isBlank())
            backend = rerankerBackend;
        backend = backend == null ? "" : backend.trim().toLowerCase(java.util.Locale.ROOT);

        boolean onnxAllowed = onnxEnabledOverride != Boolean.FALSE && metaBool(metaMap, "onnx.enabled", true);
        boolean onnxBreakerOpen = false;
        try {
            onnxBreakerOpen = (nightmareBreaker != null && nightmareBreaker.isOpen(NightmareKeys.RERANK_ONNX));
        } catch (Exception ignore) {
            // fail-soft
        }

        boolean hasOnnx = rerankers.containsKey("onnxCrossEncoderReranker");
        boolean hasEmbedding = rerankers.containsKey("embeddingCrossEncoderReranker");
        boolean hasNoop = rerankers.containsKey("noopCrossEncoderReranker");

        boolean onnxUsable = crossEncoderEnabled && onnxAllowed && hasOnnx && !onnxBreakerOpen;

        String key;
        switch (backend) {
            case "", "auto" -> {
                if (!crossEncoderEnabled) {
                    key = "noopCrossEncoderReranker";
                } else if (onnxUsable) {
                    key = "onnxCrossEncoderReranker";
                } else if (hasEmbedding) {
                    key = "embeddingCrossEncoderReranker";
                } else {
                    key = hasNoop ? "noopCrossEncoderReranker" : rerankers.keySet().iterator().next();
                }
            }
            case "onnx-runtime", "onnx" -> {
                if (!crossEncoderEnabled) {
                    key = "noopCrossEncoderReranker";
                } else if (onnxUsable) {
                    key = "onnxCrossEncoderReranker";
                } else {
                    key = hasEmbedding ? "embeddingCrossEncoderReranker"
                            : (hasNoop ? "noopCrossEncoderReranker" : rerankers.keySet().iterator().next());
                }
            }
            case "embedding-model", "embedding", "bi-encoder", "biencoder" -> key = "embeddingCrossEncoderReranker";
            case "noop", "none", "disabled" -> key = "noopCrossEncoderReranker";
            default -> key = "embeddingCrossEncoderReranker";
        }

        com.example.lms.service.rag.rerank.CrossEncoderReranker r = rerankers.get(key);
        if (r != null)
            return r;

        // final fallback order: embedding â†’ noop â†’ any
        if (hasEmbedding)
            return rerankers.get("embeddingCrossEncoderReranker");
        if (hasNoop)
            return rerankers.get("noopCrossEncoderReranker");
        return rerankers.values().iterator().next();
    }

    @Override
    public List<Content> retrieve(Query query) {

        // 0) ë©”íƒ€ íŒŒì‹±
        String sessionKey = Optional.ofNullable(query)
                .map(Query::metadata)
                .map(HybridRetriever::toMap)
                .map(md -> md.get(LangChainRAGService.META_SID))
                .map(Object::toString)
                .orElse(null);

        Map<String, Object> md = Optional.ofNullable(query)
                .map(Query::metadata)
                .map(HybridRetriever::toMap)
                .orElse(Map.of());

        @SuppressWarnings("unchecked")
        List<String> allowedDomains = (List<String>) md.getOrDefault(META_ALLOWED_DOMAINS, List.of());
        @SuppressWarnings("unchecked")
        List<String> officialDomains = (List<String>) md.getOrDefault(META_OFFICIAL_DOMAINS, allowedDomains);

        // ë©”íƒ€ì— ë“¤ì–´ì˜¨ ë³‘ë ¬ ìƒí•œ(ì—†ìœ¼ë©´ ê¸°ë³¸ì„¤ì • ì‚¬ìš©)
        int maxParallelOverride = Optional.ofNullable((Integer) md.get(META_MAX_PARALLEL)).orElse(this.maxParallel);
        String dedupeKey = (String) md.getOrDefault(META_DEDUPE_KEY, "text");

        LinkedHashSet<Content> mergedContents = new LinkedHashSet<>();

        // 1) ë‚œì´ë„ ê²Œì´íŒ…
        final String q = (query != null && query.text() != null) ? query.text().strip() : "";

        // â”€â”€ pre-fuse candidate cap (retrieveAllê³¼ ë™ì¼í•œ ì˜ë„: í›„ë³´ ìƒì„±ëŸ‰ ì œí•œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        int prefuseCap = -1;
        try {
            int keepN = metaInt(md, "rerank.topK", -1);
            if (keepN <= 0)
                keepN = metaInt(md, "rerank_top_k", -1);
            if (keepN <= 0)
                keepN = metaInt(md, "rerankTopK", -1);

            int candidateCap = metaInt(md, "rerank.ce.topK", -1);
            if (candidateCap <= 0)
                candidateCap = metaInt(md, "rerank.ceTopK", -1);
            if (candidateCap <= 0)
                candidateCap = metaInt(md, "rerank_ce_top_k", -1);
            if (candidateCap <= 0)
                candidateCap = metaInt(md, "rerankCeTopK", -1);
            if (candidateCap <= 0)
                candidateCap = metaInt(md, "rerank.candidateK", -1);
            if (candidateCap <= 0)
                candidateCap = metaInt(md, "rerank.candidate_k", -1);
            if (candidateCap <= 0)
                candidateCap = metaInt(md, "rerank_candidate_k", -1);
            if (candidateCap <= 0)
                candidateCap = metaInt(md, "rerankCandidateK", -1);

            if (candidateCap <= 0 && keepN > 0) {
                candidateCap = Math.max(keepN * 2, Math.max(keepN, topK));
            }

            if (candidateCap > 0) {
                prefuseCap = (keepN > 0) ? Math.max(candidateCap, keepN) : candidateCap;
            }
        } catch (Exception ignore) {
            // fail-soft
        }

        final boolean applyPrefuseCap = prefuseCap > 0;
        final int maxCandidates = applyPrefuseCap ? Math.max(1, prefuseCap) : Integer.MAX_VALUE;
        final int minNeed = applyPrefuseCap ? Math.max(1, Math.min(topK, maxCandidates)) : topK;

        if (applyPrefuseCap) {
            try {
                TraceStore.put("rerank.prefuse.cap", maxCandidates);
                TraceStore.put("rerank.prefuse.minNeed", minNeed);
            } catch (Exception ignore) {
            }

            // Cap lane topKs only downward (never increase defaults).
            // Rebuild Query so downstream retrievers observe caps consistently.
            try {
                java.util.Map<String, Object> md2 = new java.util.HashMap<>();
                if (md != null && !md.isEmpty()) {
                    md2.putAll(md);
                }

                int w = metaInt(md2, "webTopK", -1);
                if (w > maxCandidates)
                    md2.put("webTopK", String.valueOf(maxCandidates));

                int v = metaInt(md2, "vecTopK", -1);
                if (v > maxCandidates)
                    md2.put("vecTopK", String.valueOf(maxCandidates));

                int vt = metaInt(md2, "vectorTopK", -1);
                if (vt > maxCandidates)
                    md2.put("vectorTopK", String.valueOf(maxCandidates));

                int kg = metaInt(md2, "kgTopK", -1);
                if (kg > maxCandidates)
                    md2.put("kgTopK", String.valueOf(maxCandidates));

                query = QueryUtils.buildQuery(q, sessionKey, null, md2);
                md = md2;
            } catch (Exception ignore) {
                // fail-soft
            }
        }

        // Determine the query domain once up front. When the domain detector is
        // unavailable default to GENERAL. The domain is used when selecting
        // which Pinecone index to query via chooseIndex().
        String detectedDomain;
        try {
            detectedDomain = (domainDetector != null) ? domainDetector.detect(q) : "GENERAL";
        } catch (Exception ignore) {
            detectedDomain = "GENERAL";
        }
        final String chosenIndex = chooseIndex(detectedDomain);

        // â”€â”€ ì¡°ê±´ë¶€ íŒŒì´í”„ë¼ì¸: êµìœ¡/í›ˆë ¨ Intent ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ëª¨ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try {
            boolean isEducationIntent = "EDU".equalsIgnoreCase(detectedDomain)
                    || "EDUCATION".equalsIgnoreCase(detectedDomain);

            // Query metadataì—ì„œ intent íŒíŠ¸ ì½ê¸° (ì„ í–‰ Preprocessorê°€ ì±„ì› ë‹¤ê³  ê°€ì •)
            String intentFromMeta = null;
            try {
                if (md != null) {
                    Object raw = md.get("intent");
                    if (raw instanceof String s) {
                        intentFromMeta = s;
                    }
                }
            } catch (Exception ignore) {
                // ë©”íƒ€ íŒŒì‹± ì¥ì• ëŠ” ë¬´ì‹œí•˜ê³  ê¸°ë³¸ ë„ë©”ì¸ë§Œ ì‚¬ìš©
            }
            if ("education".equalsIgnoreCase(intentFromMeta)
                    || "training".equalsIgnoreCase(intentFromMeta)) {
                isEducationIntent = true;
            }

            if (isEducationIntent) {
                log.debug("[Hybrid] Education intent â†’ vector-only retrieval (index={})", chosenIndex);
                ContentRetriever pineRetriever = ragService.asContentRetriever(chosenIndex);
                List<Content> vectResults = pineRetriever.retrieve(query);
                List<Content> filteredVectResults = (vectResults == null) ? java.util.Collections.emptyList()
                        : vectResults.stream().filter(this::allowVectorChunk).collect(Collectors.toList());
                // deduplicate results while preserving order
                LinkedHashSet<Content> unique = new LinkedHashSet<>(filteredVectResults);
                List<Content> deduped = new ArrayList<>(unique);
                // rank by cosine similarity.
                try {
                    deduped.sort((c1, c2) -> {
                        String t1 = java.util.Optional.ofNullable(c1.textSegment())
                                .map(dev.langchain4j.data.segment.TextSegment::text)
                                .orElse(c1.toString());
                        String t2 = java.util.Optional.ofNullable(c2.textSegment())
                                .map(dev.langchain4j.data.segment.TextSegment::text)
                                .orElse(c2.toString());
                        double s1 = cosineSimilarity(q, t1);
                        double s2 = cosineSimilarity(q, t2);
                        return Double.compare(s2, s1);
                    });
                } catch (Exception ignore) {
                    // if ranking fails, maintain original order
                }
                // limit to topK
                List<Content> topList = deduped.size() > topK ? deduped.subList(0, topK) : deduped;
                // finalise and return
                return finalizeResults(new ArrayList<>(topList), dedupeKey, officialDomains, q, md);
            }
        } catch (Exception ignore) {
            // on error continue with default behaviour
        }

        QueryComplexityGate.Level level = gate.assess(q);
        log.debug("[Hybrid] level={} q='{}'", level, q);

        switch (level) {
            case SIMPLE -> {
                // ë‹¨ìˆœ ì§ˆì˜: WebSearchRetriever ë¨¼ì €, ì—†ìœ¼ë©´ Vectorë¡œ fallback.
                List<Content> webResults = Collections.emptyList();
                try {
                    webResults = webSearchRetriever.retrieve(query);
                } catch (Exception e) {
                    log.warn("[HybridRetriever] Web search failed: {}", e.toString());
                }

                if (webResults != null && !webResults.isEmpty()) {
                    addCapped(mergedContents, webResults, maxCandidates);
                } else {
                    ContentRetriever pine = ragService.asContentRetriever(chosenIndex);
                    List<Content> raw = pine.retrieve(query);
                    if (raw != null) {
                        addCapped(
                                mergedContents,
                                raw.stream().filter(this::allowVectorChunk).collect(Collectors.toList()),
                                maxCandidates);
                    }
                }

                if (mergedContents.size() < minNeed && mergedContents.size() < maxCandidates
                        && tavilyWebSearchRetriever != null) {
                    try {
                        addCapped(mergedContents, tavilyWebSearchRetriever.retrieve(query), maxCandidates);
                    } catch (Exception e) {
                        log.debug("[Hybrid] Tavily fallback skipped: {}", e.toString());
                    }
                }
            }
            case AMBIGUOUS -> {
                addCapped(mergedContents, analyzeRetriever.retrieve(query), maxCandidates);

                if (mergedContents.size() < minNeed && mergedContents.size() < maxCandidates) {
                    addCapped(mergedContents, webSearchRetriever.retrieve(query), maxCandidates);
                }

                if (mergedContents.size() < minNeed && mergedContents.size() < maxCandidates) {
                    ContentRetriever pine = ragService.asContentRetriever(chosenIndex);
                    List<Content> raw = pine.retrieve(query);
                    if (raw != null) {
                        addCapped(
                                mergedContents,
                                raw.stream().filter(this::allowVectorChunk).collect(Collectors.toList()),
                                maxCandidates);
                    }
                }

                if (mergedContents.size() < minNeed && mergedContents.size() < maxCandidates
                        && tavilyWebSearchRetriever != null) {
                    try {
                        addCapped(mergedContents, tavilyWebSearchRetriever.retrieve(query), maxCandidates);
                    } catch (Exception e) {
                        log.debug("[Hybrid] Tavily fallback skipped: {}", e.toString());
                    }
                }
            }
            case COMPLEX -> {
                addCapped(mergedContents, selfAskRetriever.retrieve(query), maxCandidates);

                if (mergedContents.size() < minNeed && mergedContents.size() < maxCandidates) {
                    addCapped(mergedContents, analyzeRetriever.retrieve(query), maxCandidates);
                }

                if (mergedContents.size() < minNeed && mergedContents.size() < maxCandidates) {
                    addCapped(mergedContents, webSearchRetriever.retrieve(query), maxCandidates);
                }

                if (mergedContents.size() < minNeed && mergedContents.size() < maxCandidates) {
                    ContentRetriever pine = ragService.asContentRetriever(chosenIndex);
                    List<Content> raw = pine.retrieve(query);
                    if (raw != null) {
                        addCapped(
                                mergedContents,
                                raw.stream().filter(this::allowVectorChunk).collect(Collectors.toList()),
                                maxCandidates);
                    }
                }

                if (mergedContents.size() < minNeed && mergedContents.size() < maxCandidates
                        && tavilyWebSearchRetriever != null) {
                    try {
                        addCapped(mergedContents, tavilyWebSearchRetriever.retrieve(query), maxCandidates);
                    } catch (Exception e) {
                        log.debug("[Hybrid] Tavily fallback skipped: {}", e.toString());
                    }
                }
            }
        }

        // ìµœì¢… ì •ì œ
        List<Content> out = finalizeResults(new ArrayList<>(mergedContents), dedupeKey, officialDomains, q, md);

        // â”€ ì•”ë¬µ í”¼ë“œë°±(ê²€ìƒ‰ ì¼ê´€ì„±) ë°˜ì˜
        try {
            maybeRecordImplicitConsistency(q, out, officialDomains);
        } catch (Exception ignore) {
        }

        return out;
    }

    private static void addCapped(java.util.Set<Content> dst, java.util.List<Content> src, int cap) {
        if (dst == null || src == null || src.isEmpty()) {
            return;
        }
        if (cap <= 0 || cap == Integer.MAX_VALUE) {
            dst.addAll(src);
            return;
        }
        for (Content c : src) {
            if (c == null) {
                continue;
            }
            dst.add(c);
            if (dst.size() >= cap) {
                break;
            }
        }
    }

    /**
     * ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì˜¤ì—¼ ì²­í¬ í•„í„°ë§ (fail-soft).
     *
     * <ul>
     * <li>ë©”íƒ€ ì—†ìœ¼ë©´ í†µê³¼ (ë ˆê±°ì‹œ í˜¸í™˜)</li>
     * <li>ASSISTANT + verified=false ëŠ” ì°¨ë‹¨</li>
     * </ul>
     */
    private boolean allowVectorChunk(Content c) {
        if (c == null)
            return false;

        java.util.Map<?, ?> md = null;
        try {
            var seg = c.textSegment();
            if (seg != null && seg.metadata() != null) {
                md = seg.metadata().toMap();
            }
        } catch (Exception ignore) {
        }

        if (md == null || md.isEmpty()) {
            return true; // ë ˆê±°ì‹œ ë°ì´í„°ëŠ” í†µê³¼
        }

        Object sourceTagRaw = md.get(VectorMetaKeys.META_SOURCE_TAG);
        String sourceTag = sourceTagRaw != null ? String.valueOf(sourceTagRaw) : "";
        Object originRaw = md.get(VectorMetaKeys.META_ORIGIN);
        String origin = originRaw != null ? String.valueOf(originRaw) : "";
        Object verifiedObj = md.get(VectorMetaKeys.META_VERIFIED);

        boolean verified = (verifiedObj instanceof Boolean b)
                ? b
                : "true".equalsIgnoreCase(String.valueOf(verifiedObj));

        boolean isAssistant = "ASSISTANT".equalsIgnoreCase(sourceTag)
                || "LLM".equalsIgnoreCase(origin);

        if (isAssistant && !verified) {
            log.debug("[Hybrid] Filtering out unverified ASSISTANT chunk");
            return false;
        }

        return true;
    }

    private static boolean containsAny(String text, String[] cues) {
        if (text == null)
            return false;
        String t = text.toLowerCase(java.util.Locale.ROOT);
        for (String c : cues)
            if (t.contains(c))
                return true;
        return false;
    }

    private static final String[] SYNERGY_CUES = { "ì‹œë„ˆì§€", "ì¡°í•©", "ê¶í•©", "í•¨ê»˜", "ì–´ìš¸", "ì½¤ë³´" };

    private void maybeRecordImplicitConsistency(String queryText, List<Content> contents,
            List<String> officialDomains) {
        if (scoring == null || kb == null || contents == null || contents.isEmpty())
            return;
        String domain = kb.inferDomain(queryText);
        var ents = kb.findMentionedEntities(domain, queryText);
        if (ents == null || ents.size() < 2)
            return;
        var it = ents.iterator();
        String subject = it.next();
        String partner = it.next();
        int total = 0, hit = 0;
        for (Content c : contents) {
            String text = java.util.Optional.ofNullable(c.textSegment())
                    .map(dev.langchain4j.data.segment.TextSegment::text)
                    .orElse(c.toString());
            String url = extractUrl(text);
            boolean both = text != null
                    && text.toLowerCase(java.util.Locale.ROOT).contains(subject.toLowerCase(java.util.Locale.ROOT))
                    && text.toLowerCase(java.util.Locale.ROOT).contains(partner.toLowerCase(java.util.Locale.ROOT));
            if (both) {
                total++;
                double w = containsAny(text, SYNERGY_CUES) ? 1.0 : 0.6; // ì‹œë„ˆì§€ ë‹¨ì„œ ë³´ë„ˆìŠ¤
                if (isOfficial(url, officialDomains))
                    w += 0.1; // ê³µì‹ ë„ë©”ì¸ ë³´ë„ˆìŠ¤
                if (w >= 0.9)
                    hit++; // ê°•í•œ ì§€ì§€ë¡œ ì¹´ìš´íŠ¸
            }
        }
        if (total <= 0)
            return;
        double consistency = hit / (double) total;
        scoring.applyImplicitPositive(domain, subject, partner, consistency);
        // If the consistency score is high enough, attempt to persist the path for
        // future alignment.
        try {
            if (pathFormation != null) {
                pathFormation.maybeFormPath(subject + "->" + partner, consistency);
            }
        } catch (Throwable ignore) {
            // path reinforcement failures should not break retrieval
        }
    }

    /**
     * Progressive retrieval:
     * 1) Local RAG ìš°ì„  â†’ í’ˆì§ˆ ì¶©ë¶„ ì‹œ ì¡°ê¸° ì¢…ë£Œ
     * 2) ë¯¸í¡ ì‹œ Self-Ask(1~2ê°œ)ë¡œ ì •ì œëœ ì›¹ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
     */
    @Deprecated // â† í­í¬ìˆ˜ ê²€ìƒ‰ ë¹„í™œì„±í™” ê²½ë¡œ(ë‚¨ê²¨ë‘ë˜ í˜¸ì¶œì€ ë‚¨ê¹€)
    public List<Content> retrieveProgressive(String question, String sessionKey, int limit) {
        if (question == null || question.isBlank()) {
            return List.of(Content.from("[ë¹ˆ ì§ˆì˜]"));
        }
        final int top = Math.max(1, limit);

        try {
            // 1) ë¡œì»¬ RAG ìš°ì„ 
            // Detect the domain of the question and select the appropriate pinecone index.
            String domain;
            try {
                domain = (domainDetector != null) ? domainDetector.detect(question) : "GENERAL";
            } catch (Exception ignore) {
                domain = "GENERAL";
            }
            String idx = chooseIndex(domain);
            ContentRetriever pine = ragService.asContentRetriever(idx);
            // [HARDENING] build query with metadata for session isolation
            String sidForQuery = (sessionKey == null || sessionKey.isBlank()) ? "__TRANSIENT__" : sessionKey;
            dev.langchain4j.rag.query.Query qObj = QueryUtils.buildQuery(question, sidForQuery, null);
            Map<String, Object> md0 = toMap(qObj.metadata());

            // â”€â”€ pre-fuse candidate cap (retrieveAll/retrieveì™€ ë™ì¼í•œ ì˜ë„: í›„ë³´ ìƒì„±ëŸ‰ ì œí•œ)
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            int prefuseCap = -1;
            int fuseLimit = top;
            try {
                int keepN = metaInt(md0, "rerank.topK", -1);
                if (keepN <= 0)
                    keepN = metaInt(md0, "rerank_top_k", -1);
                if (keepN <= 0)
                    keepN = metaInt(md0, "rerankTopK", -1);

                int candidateCap = metaInt(md0, "rerank.ce.topK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(md0, "rerank.ceTopK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(md0, "rerank_ce_top_k", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(md0, "rerankCeTopK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(md0, "rerank.candidateK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(md0, "rerank.candidate_k", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(md0, "rerank_candidate_k", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(md0, "rerankCandidateK", -1);

                if (candidateCap <= 0 && keepN > 0) {
                    candidateCap = Math.max(keepN * 2, Math.max(keepN, top));
                }

                if (candidateCap > 0) {
                    prefuseCap = (keepN > 0) ? Math.max(candidateCap, keepN) : candidateCap;
                    fuseLimit = Math.min(fuseLimit, Math.max(1, prefuseCap));
                    TraceStore.put("rerank.prefuse.cap", prefuseCap);
                    TraceStore.put("rerank.prefuse.limit", fuseLimit);
                }
            } catch (Exception ignore) {
                // fail-soft
            }
            final boolean applyPrefuseCap = prefuseCap > 0;

            List<Content> local = pine.retrieve(qObj);

            if (applyPrefuseCap && local != null && local.size() > fuseLimit) {
                local = new java.util.ArrayList<>(local.subList(0, fuseLimit));
            }

            if (qualityEvaluator != null
                    && qualityEvaluator.isSufficient(question, local, qualityMinDocs, qualityMinScore)) {
                log.info("[Hybrid] Local RAG sufficient â†’ skip web (sid={}, q='{}')", sessionKey, question);
                List<Content> out = finalizeResults(new ArrayList<>(local), "text", java.util.Collections.emptyList(),
                        question, md0);
                return out.size() > top ? out.subList(0, top) : out;
            }

            // 2) Self-Askë¡œ 1~2ê°œ í•µì‹¬ ì§ˆì˜ ìƒì„± â†’ ìœ„ìƒ í•„í„°
            List<String> planned;
            if (!selfAskEnabled || selfAskPlanner == null) {
                planned = List.of(question);
            } else {
                try {
                    planned = selfAskPlanner.plan(question, 2);
                } catch (Exception e) {
                    log.warn("[Hybrid] SelfAskPlanner ì‹¤íŒ¨(sid={}, q='{}'): {} â†’ fallback to raw query",
                            sessionKey, question, e.toString());
                    planned = List.of(question);
                }
            }
            List<String> queries = QueryHygieneFilter.sanitize(planned, 2, 0.80);

            if (queries.isEmpty())
                queries = List.of(question);
            if (queries.isEmpty())
                queries = List.of(question);

            // 3) í•„ìš”í•œ ì¿¼ë¦¬ë§Œ ìˆœì°¨ ì²˜ë¦¬ â†’ ìœµí•©
            List<List<Content>> buckets = new ArrayList<>();
            for (String q : queries) {
                List<Content> acc = new ArrayList<>();
                try {
                    // [HARDENING] build a query with session metadata using QueryUtils
                    java.util.Map<String, Object> mdSub = new java.util.HashMap<>();
                    if (md0 != null && !md0.isEmpty()) {
                        mdSub.putAll(md0);
                    }

                    // pre-fuse ë‹¨ê³„ì—ì„œ lane topKë„ cap (retriever ë¹„ìš© ì ˆê°)
                    if (applyPrefuseCap) {
                        int w = metaInt(mdSub, "webTopK", -1);
                        if (w > fuseLimit)
                            mdSub.put("webTopK", String.valueOf(fuseLimit));
                        int v = metaInt(mdSub, "vecTopK", -1);
                        if (v > fuseLimit)
                            mdSub.put("vecTopK", String.valueOf(fuseLimit));
                        int vt = metaInt(mdSub, "vectorTopK", -1);
                        if (vt > fuseLimit)
                            mdSub.put("vectorTopK", String.valueOf(fuseLimit));
                        int kg = metaInt(mdSub, "kgTopK", -1);
                        if (kg > fuseLimit)
                            mdSub.put("kgTopK", String.valueOf(fuseLimit));
                    }

                    mdSub.put("subQuery", "true");
                    dev.langchain4j.rag.query.Query subQ = QueryUtils.buildQuery(q, sidForQuery, null, mdSub);
                    handlerChain.handle(subQ, acc);

                    if (applyPrefuseCap && acc.size() > fuseLimit) {
                        acc = new java.util.ArrayList<>(acc.subList(0, fuseLimit));
                    }
                } catch (Exception e) {
                    log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", e.toString());
                }
                buckets.add(acc);
            }

            // ìœµí•© ë° ìµœì¢… ì •ì œ í›„ ìƒìœ„ top ë°˜í™˜
            // Select the fusion strategy. Softmax fusion is enabled only when
            // the mode is set to 'softmax' and a valid calibration is provided.
            List<Content> fused;
            boolean useSoftmax = "softmax".equalsIgnoreCase(fusionMode)
                    && ("minmax".equalsIgnoreCase(softmaxCalibration)
                            || "isotonic".equalsIgnoreCase(softmaxCalibration));
            final int fuseK = applyPrefuseCap ? Math.max(1, Math.min(fuseLimit, top)) : top;
            if (useSoftmax) {
                fused = fuseWithSoftmax(buckets, fuseK, question);
            } else {
                // Weighted RRF support: if the fusion mode is marked as weighted
                // and a weighted fuser is available, prefer it over the
                // unweighted RRF. Recognised values include "weighted-rrf",
                // "rrf-weighted" and "weighted".
                boolean useWeighted = weightedFuser != null &&
                        ("weighted-rrf".equalsIgnoreCase(fusionMode) ||
                                "rrf-weighted".equalsIgnoreCase(fusionMode) ||
                                "weighted".equalsIgnoreCase(fusionMode));
                if (useWeighted) {
                    fused = weightedFuser.fuse(buckets, fuseK);
                } else {
                    fused = fuser.fuse(buckets, fuseK);
                }
            }
            List<Content> combined = new ArrayList<>(local); // 'local'ì€ ì´ ë©”ì†Œë“œ ìƒë‹¨ì—ì„œ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
            combined.addAll(fused);

            List<Content> out = finalizeResults(combined, "text", java.util.Collections.emptyList(), question, md0);
            return out.size() > top ? out.subList(0, top) : out;

        } catch (Exception e) {
            log.error("[Hybrid] retrieveProgressive ì‹¤íŒ¨(sid={}, q='{}')", sessionKey, question, e);
            return List.of(Content.from("[ê²€ìƒ‰ ì˜¤ë¥˜]"));
        }
    }

    /**
     * Progressive retrieval with optional routing hints. This overload accepts a
     * map of
     * metadata hints (precision search, depth, webTopK, etc.) which will be
     * embedded into
     * the Query metadata. When hints are provided the downstream web search handler
     * can
     * adjust its behaviour accordingly (e.g. precision scanning). When no hints are
     * provided the default behaviour is equivalent to the legacy
     * retrieveProgressive
     * method.
     *
     * @param question   the user question
     * @param sessionKey unique session identifier for isolation
     * @param limit      number of items to return
     * @param metaHints  optional metadata hints to embed into the query
     * @return list of retrieved content
     */
    public java.util.List<Content> retrieveProgressive(String question, String sessionKey, int limit,
            java.util.Map<String, Object> metaHints) {
        if (question == null || question.isBlank()) {
            return java.util.List.of(Content.from("[ë¹ˆ ì§ˆì˜]"));
        }
        final int top = Math.max(1, limit);

        try {
            // 1) Local RAG first
            String domain;
            try {
                domain = (domainDetector != null) ? domainDetector.detect(question) : "GENERAL";
            } catch (Exception ignore) {
                domain = "GENERAL";
            }
            String idx = chooseIndex(domain);
            ContentRetriever pine = ragService.asContentRetriever(idx);
            String sidForQuery = (sessionKey == null || sessionKey.isBlank()) ? "__TRANSIENT__" : sessionKey;
            // Merge default metadata with hints and SID
            java.util.Map<String, Object> mdMap = new java.util.HashMap<>();
            mdMap.put(com.example.lms.service.rag.LangChainRAGService.META_SID, sidForQuery);
            if (metaHints != null)
                mdMap.putAll(metaHints);
            mdMap.putIfAbsent("depth", "LIGHT");
            mdMap.putIfAbsent("webTopK", top);

            // â”€â”€ pre-fuse candidate cap (retrieveAll/retrieveì™€ ë™ì¼í•œ ì˜ë„: í›„ë³´ ìƒì„±ëŸ‰ ì œí•œ)
            // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            // rerank_ce_top_k / rerank_candidate_këŠ” ì›ë˜ CE ì…ë ¥ í›„ë³´ ì»· ìš©ë„ì§€ë§Œ,
            // progressive ê²½ë¡œì—ì„œë„ "fuse ì´ì „ í›„ë³´ ìƒì„±ëŸ‰"ì„ ê°™ì´ ì œí•œí•˜ë©´ ë¹„ìš©/ì§€ì—°ì„ ë” ì¤„ì¼ ìˆ˜ ìˆë‹¤.
            int prefuseCap = -1;
            int fuseLimit = top;
            try {
                int keepN = metaInt(mdMap, "rerank.topK", -1);
                if (keepN <= 0)
                    keepN = metaInt(mdMap, "rerank_top_k", -1);
                if (keepN <= 0)
                    keepN = metaInt(mdMap, "rerankTopK", -1);

                int candidateCap = metaInt(mdMap, "rerank.ce.topK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(mdMap, "rerank.ceTopK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(mdMap, "rerank_ce_top_k", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(mdMap, "rerankCeTopK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(mdMap, "rerank.candidateK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(mdMap, "rerank.candidate_k", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(mdMap, "rerank_candidate_k", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(mdMap, "rerankCandidateK", -1);

                if (candidateCap <= 0 && keepN > 0) {
                    candidateCap = Math.max(keepN * 2, Math.max(keepN, top));
                }

                if (candidateCap > 0) {
                    prefuseCap = (keepN > 0) ? Math.max(candidateCap, keepN) : candidateCap;
                    fuseLimit = Math.min(fuseLimit, Math.max(1, prefuseCap));
                    TraceStore.put("rerank.prefuse.cap", prefuseCap);
                    TraceStore.put("rerank.prefuse.limit", fuseLimit);
                }
            } catch (Exception ignore) {
                // fail-soft
            }
            final boolean applyPrefuseCap = prefuseCap > 0;

            // pre-fuse ë‹¨ê³„ì—ì„œ lane topKë„ cap (retriever ë¹„ìš© ì ˆê°)
            if (applyPrefuseCap) {
                try {
                    int w = metaInt(mdMap, "webTopK", -1);
                    if (w > fuseLimit)
                        mdMap.put("webTopK", String.valueOf(fuseLimit));
                    int v = metaInt(mdMap, "vecTopK", -1);
                    if (v > fuseLimit)
                        mdMap.put("vecTopK", String.valueOf(fuseLimit));
                    int vt = metaInt(mdMap, "vectorTopK", -1);
                    if (vt > fuseLimit)
                        mdMap.put("vectorTopK", String.valueOf(fuseLimit));
                    int kg = metaInt(mdMap, "kgTopK", -1);
                    if (kg > fuseLimit)
                        mdMap.put("kgTopK", String.valueOf(fuseLimit));
                } catch (Exception ignore) {
                    // fail-soft
                }
            }

            dev.langchain4j.data.document.Metadata md = dev.langchain4j.data.document.Metadata.from(mdMap);
            dev.langchain4j.rag.query.Query qObj;
            try {
                qObj = new dev.langchain4j.rag.query.Query(question, md);
            } catch (Throwable t) {
                qObj = dev.langchain4j.rag.query.Query.builder().text(question).metadata(md).build();
            }
            java.util.List<Content> local = pine.retrieve(qObj);
            if (applyPrefuseCap && local != null && local.size() > fuseLimit) {
                local = new java.util.ArrayList<>(local.subList(0, fuseLimit));
            }
            if (qualityEvaluator != null
                    && qualityEvaluator.isSufficient(question, local, qualityMinDocs, qualityMinScore)) {
                java.util.List<Content> out = finalizeResults(new java.util.ArrayList<>(local), "text",
                        java.util.Collections.emptyList(), question, mdMap);
                return out.size() > top ? out.subList(0, top) : out;
            }
            // Self-Ask / hygiene filter
            java.util.List<String> planned;
            if (!selfAskEnabled || selfAskPlanner == null) {
                planned = java.util.List.of(question);
            } else {
                try {
                    planned = selfAskPlanner.plan(question, 2);
                } catch (Exception e) {
                    log.warn("[Hybrid] SelfAskPlanner ì‹¤íŒ¨(sid={}, q='{}'): {} â†’ fallback to raw query",
                            sessionKey, question, e.toString());
                    planned = java.util.List.of(question);
                }
            }
            java.util.List<String> queries = com.example.lms.search.QueryHygieneFilter.sanitize(planned, 2, 0.80);
            if (queries.isEmpty())
                queries = java.util.List.of(question);
            if (queries.isEmpty())
                queries = java.util.List.of(question);
            java.util.List<Integer> kSchedule = toIntList(mdMap.get("kSchedule"));
            java.util.List<java.util.List<Content>> buckets = new java.util.ArrayList<>();
            for (int qi = 0; qi < queries.size(); qi++) {
                String q = queries.get(qi);
                java.util.List<Content> acc = new java.util.ArrayList<>();
                try {
                    java.util.Map<String, Object> subMd = new java.util.HashMap<>(mdMap);
                    if (kSchedule != null && !kSchedule.isEmpty()) {
                        int idx2 = Math.min(qi, kSchedule.size() - 1);
                        Integer k = kSchedule.get(idx2);
                        if (k != null && k > 0) {
                            int kk = k;
                            if (applyPrefuseCap && kk > fuseLimit)
                                kk = fuseLimit;
                            subMd.put("webTopK", String.valueOf(kk));
                        }
                    }

                    // pre-fuse ë‹¨ê³„ì—ì„œ lane topKë„ cap (retriever ë¹„ìš© ì ˆê°)
                    if (applyPrefuseCap) {
                        int w = metaInt(subMd, "webTopK", -1);
                        if (w > fuseLimit)
                            subMd.put("webTopK", String.valueOf(fuseLimit));
                        int v = metaInt(subMd, "vecTopK", -1);
                        if (v > fuseLimit)
                            subMd.put("vecTopK", String.valueOf(fuseLimit));
                        int vt = metaInt(subMd, "vectorTopK", -1);
                        if (vt > fuseLimit)
                            subMd.put("vectorTopK", String.valueOf(fuseLimit));
                        int kg = metaInt(subMd, "kgTopK", -1);
                        if (kg > fuseLimit)
                            subMd.put("kgTopK", String.valueOf(fuseLimit));
                    }

                    // LangChain4j v1.0.1 does not support Boolean metadata values.
                    // Encode booleans as strings to avoid IllegalArgumentException at runtime.
                    subMd.put("subQuery", "true");
                    dev.langchain4j.data.document.Metadata subMdObj = dev.langchain4j.data.document.Metadata
                            .from(subMd);
                    dev.langchain4j.rag.query.Query subQ;
                    try {
                        subQ = new dev.langchain4j.rag.query.Query(q, subMdObj);
                    } catch (Throwable t) {
                        subQ = dev.langchain4j.rag.query.Query.builder().text(q).metadata(subMdObj).build();
                    }
                    handlerChain.handle(subQ, acc);

                    if (applyPrefuseCap && acc.size() > fuseLimit) {
                        acc = new java.util.ArrayList<>(acc.subList(0, fuseLimit));
                    }
                } catch (Exception e) {
                    log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", e.toString());
                }
                buckets.add(acc);
            }
            // Fusion and finalization
            java.util.List<Content> fused;
            boolean useSoftmax = "softmax".equalsIgnoreCase(fusionMode)
                    && ("minmax".equalsIgnoreCase(softmaxCalibration)
                            || "isotonic".equalsIgnoreCase(softmaxCalibration));
            final int fuseK = applyPrefuseCap ? Math.max(1, Math.min(fuseLimit, top)) : top;
            if (useSoftmax) {
                fused = fuseWithSoftmax(buckets, fuseK, question);
            } else {
                boolean useWeighted = weightedFuser != null &&
                        ("weighted-rrf".equalsIgnoreCase(fusionMode) ||
                                "rrf-weighted".equalsIgnoreCase(fusionMode) ||
                                "weighted".equalsIgnoreCase(fusionMode));
                if (useWeighted) {
                    fused = weightedFuser.fuse(buckets, fuseK);
                } else {
                    fused = fuser.fuse(buckets, fuseK);
                }
            }
            java.util.List<Content> combined = new java.util.ArrayList<>(local);
            combined.addAll(fused);
            java.util.List<Content> out = finalizeResults(combined, "text", java.util.Collections.emptyList(), question,
                    mdMap);
            return out.size() > top ? out.subList(0, top) : out;
        } catch (Exception e) {
            log.error("[Hybrid] retrieveProgressive ì‹¤íŒ¨(sid={}, q='{}')", sessionKey, question, e);
            return java.util.List.of(Content.from("[ê²€ìƒ‰ ì˜¤ë¥˜]"));
        }
    }

    /**
     * ë‹¤ì¤‘ ì¿¼ë¦¬ ë³‘ë ¬ ê²€ìƒ‰ + RRF ìœµí•©
     */
    public List<Content> retrieveAll(List<String> queries, int limit) {
        return retrieveAll(queries, limit, "__TRANSIENT__", null);
    }

    /**
     * ìš”ì²­ ë‹¨ìœ„ íŒíŠ¸(plate/topK/budget ë“±)ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ì „ë‹¬í•˜ëŠ” ì˜¤ë²„ë¡œë“œ.
     *
     * <p>
     * ì¤‘ìš”: ê³¼ê±° ì½”ë“œê°€ __TRANSIENT__ë¡œë§Œ Queryë¥¼ ë§Œë“¤ë©´ì„œ plateê°€ ì‹¤ì œ ê²€ìƒ‰ íŒŒë¼ë¯¸í„°ì—
     * ë°˜ì˜ë˜ì§€ ì•ŠëŠ” ë¬¸ì œê°€ ìˆì—ˆë‹¤. ì´ ë©”ì„œë“œëŠ” metaHintsë¥¼ Query metadataë¡œ ì£¼ì…í•´
     * WebSearch/SelfAsk/Analyze ë‹¨ê³„ê°€ ì‹¤ì œë¡œ ì½ì„ ìˆ˜ ìˆê²Œ í•œë‹¤.
     */
    public List<Content> retrieveAll(List<String> queries, int limit, Object sessionKey,
            java.util.Map<String, Object> metaHints) {
        if (queries == null || queries.isEmpty()) {
            return java.util.List.of();
        }

        final Object sid = (sessionKey != null ? sessionKey : "__TRANSIENT__");

        // pre-fuse candidate cap:
        // rerank_ce_top_k / rerank_candidate_këŠ” ì›ë˜ CE ì…ë ¥ í›„ë³´ ì»· ìš©ë„ì§€ë§Œ,
        // fuse ì´ì „ "í›„ë³´ ìƒì„±(limit)"ë„ ê°™ì´ ì œí•œí•˜ë©´ ë¹„ìš©/ì§€ì—°ì„ ë” ì¤„ì¼ ìˆ˜ ìˆë‹¤.
        int effectiveLimit = Math.max(1, limit);
        int prefuseCap = -1;
        try {
            if (metaHints != null && !metaHints.isEmpty()) {
                int keepN = metaInt(metaHints, "rerank.topK", -1);
                if (keepN <= 0)
                    keepN = metaInt(metaHints, "rerank_top_k", -1);
                if (keepN <= 0)
                    keepN = metaInt(metaHints, "rerankTopK", -1);

                int candidateCap = metaInt(metaHints, "rerank.ce.topK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(metaHints, "rerank_ce_top_k", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(metaHints, "rerankCeTopK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(metaHints, "rerank.candidateK", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(metaHints, "rerank_candidate_k", -1);
                if (candidateCap <= 0)
                    candidateCap = metaInt(metaHints, "rerankCandidateK", -1);

                // keepNë§Œ ìˆëŠ” ê²½ìš°: ê¸°ë³¸ìœ¼ë¡œ 2x keepN ë§Œí¼ í›„ë³´ë¥¼ ë§Œë“¤ê³  fuse í•˜ë„ë¡ ìœ ë„
                if (candidateCap <= 0 && keepN > 0) {
                    candidateCap = Math.max(keepN * 2, keepN);
                }

                if (candidateCap > 0) {
                    prefuseCap = (keepN > 0) ? Math.max(candidateCap, keepN) : candidateCap;
                    effectiveLimit = Math.min(effectiveLimit, Math.max(1, prefuseCap));
                    TraceStore.put("rerank.prefuse.cap", prefuseCap);
                    TraceStore.put("rerank.prefuse.limit", effectiveLimit);
                }
            }
        } catch (Exception ignore) {
            // fail-soft: keep original limit
        }

        final int fuseLimit = Math.max(1, effectiveLimit);
        final boolean applyPrefuseCap = prefuseCap > 0;

        try {
            java.util.List<java.util.List<Content>> results;
            if (debugSequential) {
                log.warn("[Hybrid] debug.sequential=true â†’ handlerChain ìˆœì°¨ ì‹¤í–‰");
                results = new java.util.ArrayList<>();
                for (String q : queries) {
                    java.util.List<Content> acc = new java.util.ArrayList<>();
                    try {
                        java.util.Map<String, Object> md = new java.util.HashMap<>();
                        if (metaHints != null && !metaHints.isEmpty())
                            md.putAll(metaHints);

                        // pre-fuse ë‹¨ê³„ì—ì„œ lane topKë„ cap (retriever ë¹„ìš© ì ˆê°)
                        if (applyPrefuseCap) {
                            int w = metaInt(md, "webTopK", -1);
                            if (w > fuseLimit)
                                md.put("webTopK", String.valueOf(fuseLimit));
                            int v = metaInt(md, "vecTopK", -1);
                            if (v > fuseLimit)
                                md.put("vecTopK", String.valueOf(fuseLimit));
                            int vt = metaInt(md, "vectorTopK", -1);
                            if (vt > fuseLimit)
                                md.put("vectorTopK", String.valueOf(fuseLimit));
                            int kg = metaInt(md, "kgTopK", -1);
                            if (kg > fuseLimit)
                                md.put("kgTopK", String.valueOf(fuseLimit));
                        }

                        md.put("subQuery", "true");
                        dev.langchain4j.rag.query.Query subQ = QueryUtils.buildQuery(q, sid, null, md);
                        handlerChain.handle(subQ, acc);

                        if (applyPrefuseCap && acc.size() > fuseLimit) {
                            acc = new java.util.ArrayList<>(acc.subList(0, fuseLimit));
                        }
                    } catch (Exception e) {
                        log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", q, e);
                    }
                    results.add(acc);
                }
            } else {
                // ê¸°ë³¸: ì œí•œ ë³‘ë ¬ ì‹¤í–‰ (ê³µìš© í’€ ì‚¬ìš© ê¸ˆì§€)
                //
                // UAW: ë³‘ë ¬ í•©ì„±ë¶€ì—ì„œ MDC/GuardContext/TraceStore ì „íŒŒê°€ ëŠê¸°ë©´
                // handlerChainì´ "passë§Œ" ë°˜ë³µí•˜ë‹¤ê°€ ê²°ê³¼ê°€ 0ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ì¼€ì´ìŠ¤ê°€ ìˆë‹¤.
                // ContextPropagationìœ¼ë¡œ taskë¥¼ ê°ì‹¸ ìš”ì²­ ë‹¨ìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•œë‹¤.
                java.util.concurrent.ExecutorService pool = java.util.concurrent.Executors.newFixedThreadPool(
                        Math.max(1, this.maxParallel));
                try {
                    java.util.List<java.util.concurrent.CompletableFuture<java.util.List<Content>>> futures =
                            new java.util.ArrayList<>(queries.size());

                    for (String q : queries) {
                        futures.add(java.util.concurrent.CompletableFuture.supplyAsync(
                                com.example.lms.infra.exec.ContextPropagation.wrapSupplier(() -> {
                                    java.util.List<Content> acc = new java.util.ArrayList<>();
                                    try {
                                        java.util.Map<String, Object> md = new java.util.HashMap<>();
                                        if (metaHints != null && !metaHints.isEmpty())
                                            md.putAll(metaHints);

                                        // pre-fuse ë‹¨ê³„ì—ì„œ lane topKë„ cap (retriever ë¹„ìš© ì ˆê°)
                                        if (applyPrefuseCap) {
                                            int w = metaInt(md, "webTopK", -1);
                                            if (w > fuseLimit)
                                                md.put("webTopK", String.valueOf(fuseLimit));
                                            int v = metaInt(md, "vecTopK", -1);
                                            if (v > fuseLimit)
                                                md.put("vecTopK", String.valueOf(fuseLimit));
                                            int vt = metaInt(md, "vectorTopK", -1);
                                            if (vt > fuseLimit)
                                                md.put("vectorTopK", String.valueOf(fuseLimit));
                                            int kg = metaInt(md, "kgTopK", -1);
                                            if (kg > fuseLimit)
                                                md.put("kgTopK", String.valueOf(fuseLimit));
                                        }

                                        md.put("subQuery", "true");
                                        dev.langchain4j.rag.query.Query subQ = QueryUtils.buildQuery(q, sid, null, md);
                                        handlerChain.handle(subQ, acc);
                                    } catch (Exception e) {
                                        log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", q, e);
                                    }

                                    if (applyPrefuseCap && acc.size() > fuseLimit) {
                                        return new java.util.ArrayList<>(acc.subList(0, fuseLimit));
                                    }
                                    return acc;
                                }), pool));
                    }

                    results = futures.stream()
                            .map(f -> {
                                try {
                                    return f.join();
                                } catch (Exception e) {
                                    return java.util.List.<Content>of();
                                }
                            })
                            .toList();
                } finally {
                    pool.shutdown();
                }
            }

            // RRF or Softmax ìœµí•© í›„ ìƒìœ„ limit ë°˜í™˜
            boolean useSoftmax = "softmax".equalsIgnoreCase(fusionMode)
                    && ("minmax".equalsIgnoreCase(softmaxCalibration)
                            || "isotonic".equalsIgnoreCase(softmaxCalibration));
            if (useSoftmax) {
                String q0 = queries.get(0); // representative query (approximation)
                return fuseWithSoftmax(results, fuseLimit, q0);
            }

            boolean useWeighted = weightedFuser != null &&
                    ("weighted-rrf".equalsIgnoreCase(fusionMode) ||
                            "rrf-weighted".equalsIgnoreCase(fusionMode) ||
                            "weighted".equalsIgnoreCase(fusionMode));
            if (useWeighted) {
                return weightedFuser.fuse(results, fuseLimit);
            }
            return fuser.fuse(results, fuseLimit);
        } catch (Exception e) {
            log.error("[Hybrid] retrieveAll ì‹¤íŒ¨", e);
            return java.util.List.of(Content.from("[ê²€ìƒ‰ ì˜¤ë¥˜]"));
        }
    } // retrieveAll ë

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // ìƒíƒœ ê¸°ë°˜ ê²€ìƒ‰: CognitiveState/PromptContextë¥¼ ë°˜ì˜í•´ ì¿¼ë¦¬ í™•ì¥ â†’ ë³‘ë ¬ ê²€ìƒ‰
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    public List<Content> retrieveStateDriven(PromptContext ctx, int limit) {
        String userQ = Optional.ofNullable(ctx.userQuery()).orElse("");
        String lastA = ctx.lastAssistantAnswer();
        String subject = ctx.subject();
        // QueryTransformerì˜ í™•ì¥ API í™œìš©
        List<String> queries = queryTransformer.transformEnhanced(userQ, lastA, subject);
        if (queries.isEmpty())
            queries = List.of(userQ);
        return retrieveAll(queries, Math.max(1, limit));
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * (ì˜µì…˜) ì½”ì‚¬ì¸ ìœ ì‚¬ë„ - í•„ìš” ì‹œ ì‚¬ìš©
     */
    private double cosineSimilarity(String q, String doc) {
        try {
            var qVec = embeddingModel.embed(q).content().vector();
            var dVec = embeddingModel.embed(doc).content().vector();
            if (qVec.length != dVec.length) {
                throw new IllegalArgumentException("Embedding dimension mismatch");
            }
            double dot = 0, nq = 0, nd = 0;
            for (int i = 0; i < qVec.length; i++) {
                dot += qVec[i] * dVec[i];
                nq += qVec[i] * qVec[i];
                nd += dVec[i] * dVec[i];
            }
            if (nq == 0 || nd == 0)
                return 0d;
            return dot / (Math.sqrt(nq) * Math.sqrt(nd) + 1e-9);
        } catch (Exception e) {
            return 0d;
        }
    }

    @SuppressWarnings("unchecked")
    private static Map<String, Object> toMap(Object meta) {
        if (meta == null)
            return Map.of();
        // LangChain4j 1.0.x: rag.query.Metadata â†’ chatMemoryId ë° asMap ì§€ì›
        if (meta instanceof dev.langchain4j.rag.query.Metadata m) {
            java.util.Map<String, Object> out = new java.util.HashMap<>();
            try {
                java.util.Map<String, Object> inner = m.asMap();
                if (inner != null) {
                    out.putAll(inner);
                }
            } catch (Exception ignore) {
                // asMap ì‚¬ìš© ë¶ˆê°€ ì‹œ chatMemoryIdë§Œ ì „ë‹¬
            }
            Object sid = m.chatMemoryId();
            if (sid != null) {
                out.put(com.example.lms.service.rag.LangChainRAGService.META_SID, sid);
            }
            return out;
        }
        if (meta instanceof java.util.Map<?, ?> raw) {
            java.util.Map<String, Object> out = new java.util.HashMap<>();
            for (java.util.Map.Entry<?, ?> e : ((java.util.Map<?, ?>) raw).entrySet()) {
                Object k = e.getKey();
                if (k != null) {
                    out.put(k.toString(), e.getValue());
                }
            }
            return out;
        }
        return java.util.Map.of();
    }

    private static boolean metaBool(Map<String, Object> md, String key, boolean defaultValue) {
        if (md == null || md.isEmpty() || key == null || key.isBlank()) {
            return defaultValue;
        }
        Object v = md.get(key);
        if (v == null) {
            return defaultValue;
        }
        if (v instanceof Boolean b) {
            return b;
        }
        String s = String.valueOf(v).trim().toLowerCase(java.util.Locale.ROOT);
        if (s.isEmpty()) {
            return defaultValue;
        }
        if ("true".equals(s) || "1".equals(s) || "yes".equals(s) || "y".equals(s)) {
            return true;
        }
        if ("false".equals(s) || "0".equals(s) || "no".equals(s) || "n".equals(s)) {
            return false;
        }
        return defaultValue;
    }

    private static String metaString(Map<String, Object> md, String key) {
        if (md == null || md.isEmpty() || key == null || key.isBlank()) {
            return null;
        }
        Object v = md.get(key);
        if (v == null) {
            return null;
        }
        String s = String.valueOf(v).trim();
        return s.isEmpty() ? null : s;
    }

    private static int metaInt(Map<String, Object> md, String key, int defaultValue) {
        if (md == null || md.isEmpty() || key == null || key.isBlank()) {
            return defaultValue;
        }
        Object v = md.get(key);
        if (v == null) {
            return defaultValue;
        }
        if (v instanceof Number n) {
            return n.intValue();
        }
        try {
            String s = String.valueOf(v).trim();
            if (s.isEmpty()) {
                return defaultValue;
            }
            return Integer.parseInt(s);
        } catch (Exception ignore) {
            return defaultValue;
        }
    }

    private static String extractUrl(String text) {
        if (text == null)
            return null;
        int a = text.indexOf("href=\"");
        if (a >= 0) {
            int s = a + 6, e = text.indexOf('"', s);
            if (e > s)
                return text.substring(s, e);
        }
        int http = text.indexOf("http");
        if (http >= 0) {
            int sp = text.indexOf(' ', http);
            return sp > http ? text.substring(http, sp) : text.substring(http);
        }
        return null;
    }

    private static boolean isOfficial(String url, List<String> officialDomains) {
        if (url == null || officialDomains == null)
            return false;
        for (String d : officialDomains) {
            if (d != null && !d.isBlank() && url.contains(d.trim()))
                return true;
        }
        return false;
    }

    /**
     * ìµœì¢… ì •ì œ:
     * - dedupeKey ê¸°ì¤€ ì¤‘ë³µ ì œê±°
     * - ê³µì‹ ë„ë©”ì¸ ë³´ë„ˆìŠ¤(+0.20)
     * - ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ topK ë°˜í™˜
     */
    private List<Content> finalizeResults(List<Content> raw,
            String dedupeKey,
            List<String> officialDomains,
            String queryText,
            Map<String, Object> meta) {

        Map<String, Object> metaMap = (meta != null) ? meta : Map.of();

        // 1) ì¤‘ë³µ ì œê±° + ì €ê´€ë ¨ í•„í„°
        Map<String, Content> uniq = new LinkedHashMap<>();
        List<Content> dropped = new ArrayList<>(); // íƒˆë½í•œ ë¬¸ì„œ ë³´ê´€ìš©
        for (Content c : raw) {
            if (c == null)
                continue;

            String text = Optional.ofNullable(c.textSegment())
                    .map(TextSegment::text)
                    .orElse(c.toString());

            double rel = 0.0;
            try {
                rel = relevanceScoringService.relatedness(
                        Optional.ofNullable(queryText).orElse(""),
                        text);
            } catch (Exception ignore) {
            }
            if (rel < minRelatedness) {
                dropped.add(c);
                continue;
            }

            String key;
            switch (dedupeKey) {
                case "url" -> key = Optional.ofNullable(extractUrl(text)).orElse(text);
                case "hash" -> key = Integer.toHexString(text.hashCode());
                default -> key = text; // "text"
            }
            uniq.putIfAbsent(key, c);
        }
        // Safety net: í•„í„°ë§ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì›ë³¸ì—ì„œ ìƒìœ„ topK ë³µêµ¬
        if (uniq.isEmpty() && !dropped.isEmpty()) {
            log.warn("[Hybrid] ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ê°€ minRelatedness({}) ë¯¸ë§Œìœ¼ë¡œ í•„í„°ë§ë¨. Safety Net ë°œë™í•˜ì—¬ ìƒìœ„ {}ê°œ ë³µêµ¬. (Query: {})",
                    minRelatedness, Math.min(topK, dropped.size()), queryText);
            for (Content c : dropped) {
                String key;
                if (dedupeKey != null && !dedupeKey.isBlank()) {
                    key = buildDedupeKey(dedupeKey, c);
                } else if (c.textSegment() != null) {
                    key = c.textSegment().text();
                } else {
                    key = null;
                }
                if (key == null || key.isBlank()) {
                    continue;
                }
                uniq.putIfAbsent(key, c);
                if (uniq.size() >= topK) {
                    break;
                }
            }
        }

        // 2) ê²½ëŸ‰ 1ì°¨ ë­í‚¹ (ì—†ìœ¼ë©´ candidates ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        List<Content> candidates = new ArrayList<>(uniq.values());
        List<Content> firstPass = (lightWeightRanker != null)
                ? lightWeightRanker.rank(
                        candidates,
                        Optional.ofNullable(queryText).orElse(""),
                        Math.max(topK * 2, 20))
                : candidates;

        // ì›ì†Œ ì œì•½ ê¸°ë°˜ ë³´ì •(ì¶”ì²œ ì˜ë„Â·ì œì•½ì€ ì „ì²˜ë¦¬ê¸°ì—ì„œ ìœ ë„)
        if (elementConstraintScorer != null) {
            try {
                firstPass = elementConstraintScorer.rescore(
                        Optional.ofNullable(queryText).orElse(""),
                        firstPass);
            } catch (Exception ignore) {
                /* ì•ˆì „ ë¬´ì‹œ */ }
        }

        // 2-B) ğŸ”´ (ì˜µì…˜) êµì°¨ì—”ì½”ë” ì¬ì •ë ¬: ì§ˆë¬¸ê³¼ì˜ ì˜ë¯¸ ìœ ì‚¬ë„ ì •ë°€ ì¬ê³„ì‚°
        // - ê°œì„ : í›„ë³´ í¬ê¸°ë¿ë§Œ ì•„ë‹ˆë¼ êµ¬ì„± ê°€ëŠ¥í•œ ì¬ë­ì»¤ ê²Œì´íŠ¸ì— ìœ„ì„í•˜ì—¬ ì‹¤í–‰ ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        // - Drift removal: plan/meta can disable CE entirely (enableCrossEncoder=false)
        // - Drift removal: plan/meta can override backend (rerank_backend) and top-k
        // (rerank_top_k)
        if (!firstPass.isEmpty()) {
            boolean shouldRerank = true;
            try {
                if (rerankGate != null) {
                    shouldRerank = rerankGate.shouldRerank(firstPass);
                }
            } catch (Exception e) {
                // Fail-soft: if the gate fails, fall back to original size check
                shouldRerank = firstPass.size() >= rerankCeTopK;
                log.debug("[Hybrid] rerankGate error {}; falling back to size check", e.toString());
            }
            // Orchestration meta gating: allow disabling expensive CE rerank.
            boolean ceEnabled = metaBool(metaMap, "enableCrossEncoder", true);
            boolean auxSuppressed = metaBool(metaMap, "nightmareMode", false)
                    || metaBool(metaMap, "auxLlmDown", false)
                    || metaBool(metaMap, "auxDegraded", false)
                    || metaBool(metaMap, "auxHardDown", false)
                    || metaBool(metaMap, "strikeMode", false)
                    || metaBool(metaMap, "compressionMode", false)
                    || metaBool(metaMap, "bypassMode", false);
            if (!ceEnabled || auxSuppressed) {
                shouldRerank = false;
                log.debug("[Hybrid] cross-encoder rerank suppressed by orchestration meta");
                try {
                    TraceStore.put("rerank.ce.skipped", true);
                    String reason = !ceEnabled ? "disabled" : "suppressed";
                    TraceStore.put("rerank.ce.skipReason", reason);
                } catch (Exception ignore) {
                }
            }
            // Select reranker per request (supports plan override + auto).
            String backendOverride = metaString(metaMap, "rerank.backend");
            if (backendOverride == null)
                backendOverride = metaString(metaMap, "rerank_backend");
            if (backendOverride == null)
                backendOverride = metaString(metaMap, "rerankBackend");
            Boolean onnxOverride = metaMap.containsKey("onnx.enabled") ? metaBool(metaMap, "onnx.enabled", true) : null;
            com.example.lms.service.rag.rerank.CrossEncoderReranker activeReranker = resolveCrossEncoderReranker(
                    metaMap, backendOverride, onnxOverride, ceEnabled);
            if (activeReranker == null) {
                shouldRerank = false;
                try {
                    TraceStore.put("rerank.ce.skipped", true);
                    TraceStore.put("rerank.ce.skipReason", "no_reranker");
                } catch (Exception ignore) {
                }
            }

            if (shouldRerank) {
                boolean allowed = true;
                // Acquire a short cooldown lock to prevent thundering herd rerank calls. When
                // the lock cannot be obtained the expensive cross-encoder rerank is skipped.
                if (cooldownService != null) {
                    try {
                        String baseKey = Optional.ofNullable(queryText).orElse("");
                        String digest = org.apache.commons.codec.digest.DigestUtils.md5Hex(baseKey);
                        String key = "ce:rerank:" + digest;
                        allowed = cooldownService.setNxEx(key, "1", 1);
                        if (!allowed) {
                            log.debug("[Hybrid] cross-encoder rerank skipped due to cooldown lock");
                            try {
                                TraceStore.put("rerank.ce.skipped", true);
                                TraceStore.put("rerank.ce.skipReason", "cooldown");
                            } catch (Exception ignore) {
                            }
                        }
                    } catch (Exception ignore) {
                        // fallback to allow rerank if lock acquisition fails
                        allowed = true;
                    }
                }
                if (allowed) {
                    try {
                        // Candidate cap: when rerank_top_k is provided by the plan, score fewer docs.
                        // Strong cost saving:
                        // - rerank_ce_top_k / rerank_candidate_k: explicit candidate cap
                        // - rerank_top_k: keepN override; if candidate cap is absent, derive cap (~2x
                        // keepN)
                        int keepK = metaInt(metaMap, "rerank.topK", -1);
                        if (keepK <= 0)
                            keepK = metaInt(metaMap, "rerank_top_k", -1);
                        if (keepK <= 0)
                            keepK = metaInt(metaMap, "rerankTopK", -1);

                        int candidateOverride = metaInt(metaMap, "rerank.ce.topK", -1);
                        if (candidateOverride <= 0)
                            candidateOverride = metaInt(metaMap, "rerank.ceTopK", -1);
                        if (candidateOverride <= 0)
                            candidateOverride = metaInt(metaMap, "rerank_ce_top_k", -1);
                        if (candidateOverride <= 0)
                            candidateOverride = metaInt(metaMap, "rerankCeTopK", -1);
                        if (candidateOverride <= 0)
                            candidateOverride = metaInt(metaMap, "rerank.candidateK", -1);
                        if (candidateOverride <= 0)
                            candidateOverride = metaInt(metaMap, "rerank.candidate_k", -1);
                        if (candidateOverride <= 0)
                            candidateOverride = metaInt(metaMap, "rerank_candidate_k", -1);
                        if (candidateOverride <= 0)
                            candidateOverride = metaInt(metaMap, "rerankCandidateK", -1);

                        int candidateCap;
                        if (candidateOverride > 0) {
                            candidateCap = candidateOverride;
                        } else if (keepK > 0) {
                            candidateCap = Math.max(keepK * 2, Math.max(keepK, topK));
                        } else {
                            candidateCap = Math.max(topK * 2, 20);
                        }
                        candidateCap = Math.min(candidateCap, firstPass.size());
                        // Ensure enough candidates for downstream topK/keepK needs
                        int minNeed = Math.min(topK, firstPass.size());
                        if (keepK > 0) {
                            minNeed = Math.max(minNeed, Math.min(keepK, firstPass.size()));
                        }
                        if (candidateCap < minNeed) {
                            candidateCap = minNeed;
                        }

                        List<Content> ceInput = firstPass;
                        if (candidateCap < firstPass.size()) {
                            ceInput = firstPass.subList(0, candidateCap);
                        }

                        int topN = candidateCap;
                        if (keepK > 0) {
                            topN = Math.min(keepK, candidateCap);
                        }

                        try {
                            TraceStore.put("rerank.ce.executed", true);
                            TraceStore.put("rerank.ce.candidateCap", candidateCap);
                            TraceStore.put("rerank.ce.keepN", topN);
                            if (candidateOverride > 0)
                                TraceStore.put("rerank.ce.candidateCap.override", candidateOverride);
                        } catch (Exception ignore) {
                        }

                        log.debug("[Hybrid] cross-encoder candidateCap={} keepN={} (plan keep={}, cand={})",
                                candidateCap,
                                topN,
                                keepK,
                                candidateOverride);

                        firstPass = activeReranker.rerank(
                                Optional.ofNullable(queryText).orElse(""),
                                ceInput,
                                Math.max(1, Math.min(topN, ceInput.size())));
                        try {
                            TraceStore.put("rerank.ce.executed", true);
                        } catch (Exception ignore) {
                        }
                    } catch (Exception e) {
                        log.debug("[Hybrid] cross-encoder rerank skipped due to error: {}", e.toString());
                        try {
                            TraceStore.put("rerank.ce.skipped", true);
                            TraceStore.put("rerank.ce.skipReason", "error");
                        } catch (Exception ignore) {
                        }
                    }
                }
            } else {
                log.debug("[Hybrid] cross-encoder rerank skipped by gate");
                try {
                    TraceStore.putIfAbsent("rerank.ce.skipped", true);
                    TraceStore.putIfAbsent("rerank.ce.skipReason", "gate");
                } catch (Exception ignore) {
                }
            }
        }

        // 3) ì •ë°€ ìŠ¤ì½”ì–´ë§ + ì •ë ¬
        class Scored {
            final Content content;
            final double score;

            Scored(Content content, double score) {
                this.content = content;
                this.score = score;
            }
        }
        List<Scored> scored = new ArrayList<>();
        int rank = 0;
        // â˜… NEW: ë™ì  ë­í‚¹ ê°€ì¤‘ì¹˜/ë³´ë„ˆìŠ¤
        final double wRel = hp.getDouble("retrieval.rank.w.rel", 0.60);
        final double wBase = hp.getDouble("retrieval.rank.w.base", 0.30);
        final double wAuth = hp.getDouble("retrieval.rank.w.auth", 0.10);
        final double bonusOfficial = hp.getDouble("retrieval.rank.bonus.official", 0.20);

        // â˜… NEW: ML ë³´ì • ê³„ìˆ˜
        final double alpha = hp.getDouble("ml.correction.alpha", 0.0);
        final double beta = hp.getDouble("ml.correction.beta", 0.0);
        final double gamma = hp.getDouble("ml.correction.gamma", 0.0);
        final double d0 = hp.getDouble("ml.correction.d0", 0.0);
        final double mu = hp.getDouble("ml.correction.mu", 0.0);
        final double lambda = hp.getDouble("ml.correction.lambda", 1.0);

        for (Content c : firstPass) {
            rank++;
            double base = 1.0 / rank;

            String text = Optional.ofNullable(c.textSegment())
                    .map(TextSegment::text)
                    .orElse(c.toString());

            String url = extractUrl(text);

            double authority = authorityScorer != null ? authorityScorer.weightFor(url) : 0.5;

            double rel = 0.0;
            try {
                rel = relevanceScoringService.relatedness(
                        Optional.ofNullable(queryText).orElse(""),
                        text);
            } catch (Exception ignore) {
            }

            // â˜… NEW: ìµœì¢… ì ìˆ˜ = wRel*ê´€ë ¨ë„ + wBase*ê¸°ë³¸ë­í¬ + wAuth*Authority (+ê³µì‹ë„ë©”ì¸ ë³´ë„ˆìŠ¤)
            double score0 = (wRel * rel) + (wBase * base) + (wAuth * authority);
            if (isOfficial(url, officialDomains)) {
                score0 += bonusOfficial;
            }
            // â˜… NEW: ML ë¹„ì„ í˜• ë³´ì •(ì˜µì…˜) - ê°’åŸŸ ë³´ì • ë° tail ì œì–´
            double finalScore = useMlCorrection
                    ? MLCalibrationUtil.finalCorrection(score0, alpha, beta, gamma, d0, mu, lambda, true)
                    : score0;
            scored.add(new Scored(c, finalScore));
        }

        scored.sort((a, b) -> Double.compare(b.score, a.score));
        return scored.stream()
                .limit(topK)
                .map(s -> s.content)
                .collect(Collectors.toList());
    }

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NEW: Softmax ìœµí•©(ë‹¨ì¼ ì •ì˜ë§Œ ìœ ì§€)
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    /** ì—¬ëŸ¬ ë²„í‚·ì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ ëª¨ì•„ ì ìˆ˜(logit)ë¥¼ ë§Œë“¤ê³  softmaxë¡œ ì •ê·œí™”í•œ ë’¤ ìƒìœ„ Nì„ ê³ ë¥¸ë‹¤. */
    private List<Content> fuseWithSoftmax(List<List<Content>> buckets, int limit, String queryText) {

        // Softmax fusion weights (externalised via HyperparameterService)
        double wRelated = 0.6;
        double wAuthority = 0.1;
        double wRank = 0.3;
        try {
            if (hp != null) {
                wRelated = hp.getDouble("retrieval.fusion.softmax.w-related", wRelated);
                wAuthority = hp.getDouble("retrieval.fusion.softmax.w-authority", wAuthority);
                wRank = hp.getDouble("retrieval.fusion.softmax.w-rank", wRank);
            }
        } catch (Exception ignore) {
            // fallback to defaults on any error
        }

        Map<String, Content> keeper = new LinkedHashMap<>();
        Map<String, Double> logit = new LinkedHashMap<>();

        int bIdx = 0;
        for (List<Content> bucket : buckets) {
            if (bucket == null)
                continue;
            int rank = 0;
            for (Content c : bucket) {
                rank++;
                String text = Optional.ofNullable(c.textSegment()).map(TextSegment::text).orElse(c.toString());
                String key = Integer.toHexString(text.hashCode()); // ê°„ë‹¨ dedupe
                String url = extractUrl(text);
                double authority = (authorityScorer != null) ? authorityScorer.weightFor(url) : 0.5;
                double related = 0.0;
                try {
                    related = relevanceScoringService.relatedness(Optional.ofNullable(queryText).orElse(""), text);
                } catch (Exception ignore) {
                }
                double base = 1.0 / (rank + 0.0); // ìƒìœ„ ë­í¬ ê°€ì¤‘
                double bucketW = 1.0 / (bIdx + 1.0); // ì•ì„  ë²„í‚· ì•½ê°„ ìš°ëŒ€
                double l = (wRelated * related) + (wAuthority * authority) + (wRank * base * bucketW);

                keeper.putIfAbsent(key, c);
                logit.merge(key, l, Math::max); // ê°™ì€ ë¬¸ì„œëŠ” ê°€ì¥ ë†’ì€ logitë§Œ ìœ ì§€
            }
            bIdx++;
        }
        if (logit.isEmpty())
            return List.of();

        // softmax ì •ê·œí™”(ìˆ˜ì¹˜ ì•ˆì •í™” í¬í•¨) í›„ í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        String[] keys = logit.keySet().toArray(new String[0]);
        // Extract logits as a primitive array. These values will be calibrated
        // before applying softmax. Calibration helps ensure the logits occupy
        // a comparable range across different queries, improving the softmax
        // distribution. When calibration is disabled the original values are
        // passed through unchanged.
        double[] scores = logit.values().stream().mapToDouble(Double::doubleValue).toArray();
        try {
            if ("minmax".equalsIgnoreCase(softmaxCalibration)) {
                scores = com.example.lms.service.rag.fusion.FusionCalibrator.minMax(scores);
            } else if ("isotonic".equalsIgnoreCase(softmaxCalibration)) {
                // shim for isotonic regression. Fall back to minmax
                // scaling until an isotonic calibrator is implemented.
                scores = com.example.lms.service.rag.fusion.FusionCalibrator.minMax(scores);
            }
        } catch (Exception e) {
            log.debug("[Hybrid] softmax calibration failed: {}", e.toString());
        }
        // Compute softmax probabilities with the calibrated scores.
        double[] p = SoftmaxUtil.softmax(scores, fusionTemperature);

        // í™•ë¥  ë‚´ë¦¼ì°¨ìˆœ ìƒìœ„ limit
        java.util.List<Integer> idx = new java.util.ArrayList<>();
        for (int i = 0; i < p.length; i++)
            idx.add(i);
        idx.sort((i, j) -> Double.compare(p[j], p[i]));

        java.util.List<Content> out = new java.util.ArrayList<>();
        for (int i = 0; i < Math.min(limit, idx.size()); i++) {
            out.add(keeper.get(keys[idx.get(i)]));
        }
        return out;
    }

    // [HARDENING] ensure SID metadata is present on every query
    private dev.langchain4j.rag.query.Query ensureSidMetadata(dev.langchain4j.rag.query.Query original,
            String sessionKey) {
        // Always build a new query with the correct session metadata using QueryUtils.
        // This
        // helper constructs the proper Metadata object and avoids deprecated builder
        // APIs.
        // The chat history is omitted (null) in this context.
        return QueryUtils.buildQuery(original.text(), sessionKey, null);
    }

    // Helper to compute dedupe key consistently with finalizeResults
    private String buildDedupeKey(String dedupeKey, Content c) {
        String text = java.util.Optional.ofNullable(c.textSegment())
                .map(dev.langchain4j.data.segment.TextSegment::text)
                .orElse(c.toString());
        if ("url".equalsIgnoreCase(dedupeKey)) {
            return java.util.Optional.ofNullable(extractUrl(text)).orElse(text);
        } else if ("hash".equalsIgnoreCase(dedupeKey)) {
            return Integer.toHexString(text.hashCode());
        } else {
            return text;
        }
    }

    /**
     * Convert an Object to List of Integers (for kSchedule parsing).
     */
    private java.util.List<Integer> toIntList(Object o) {
        if (o instanceof java.util.List<?> list) {
            return list.stream()
                    .map(v -> {
                        if (v instanceof Number n)
                            return n.intValue();
                        try {
                            return Integer.parseInt(String.valueOf(v));
                        } catch (Exception e) {
                            return null;
                        }
                    })
                    .filter(java.util.Objects::nonNull)
                    .collect(java.util.stream.Collectors.toList());
        }
        return null;
    }

}
