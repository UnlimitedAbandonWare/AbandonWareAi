package com.example.lms.service.rag;

import com.example.lms.service.rag.fusion.ReciprocalRankFuser;
import com.example.lms.service.rag.handler.RetrievalHandler;
import com.example.lms.search.QueryHygieneFilter;
import com.example.lms.util.SoftmaxUtil;
import lombok.RequiredArgsConstructor;
import org.springframework.beans.factory.annotation.Autowired;
import dev.langchain4j.data.segment.TextSegment;
import dev.langchain4j.model.embedding.EmbeddingModel;
import dev.langchain4j.rag.content.Content;
import dev.langchain4j.rag.content.retriever.ContentRetriever;
import dev.langchain4j.rag.query.Query;
import dev.langchain4j.store.embedding.EmbeddingStore;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Component;
// imports
import com.example.lms.service.rag.rerank.LightWeightRanker;
import com.example.lms.service.rag.rerank.ElementConstraintScorer;  //  ì‹ ê·œ ì¬ë­ì»¤

import java.lang.reflect.Method;
import java.util.*;
import java.util.stream.Collectors;
import java.util.concurrent.ForkJoinPool;

import com.example.lms.service.rag.auth.AuthorityScorer;

import com.example.lms.service.config.HyperparameterService;   // â˜… NEW
import com.example.lms.util.MLCalibrationUtil;
@Slf4j
@Component
@RequiredArgsConstructor
public class HybridRetriever implements ContentRetriever {
    // fields (ë‹¤ë¥¸ final í•„ë“œë“¤ê³¼ ê°™ì€ ìœ„ì¹˜)
    private final LightWeightRanker lightWeightRanker;
    private final AuthorityScorer authorityScorer;
    private static final double GAME_SIM_THRESHOLD = 0.3;

    // ë©”íƒ€í‚¤ (í•„ìš” ì‹œ Query.metadataì— ì‹¤ì–´ ì „ë‹¬)
    private static final String META_ALLOWED_DOMAINS = "allowedDomains";   // List<String>
    private static final String META_MAX_PARALLEL = "maxParallel";      // Integer
    private static final String META_DEDUPE_KEY = "dedupeKey";        // "text" | "url" | "hash"
    private static final String META_OFFICIAL_DOMAINS = "officialDomains";  // List<String>

    @Value("${rag.search.top-k:5}")
    private int topK;

    // ì²´ì¸ & ìœµí•©ê¸°
    private final RetrievalHandler handlerChain;
    private final ReciprocalRankFuser fuser;
    private final AnswerQualityEvaluator qualityEvaluator;
    private final SelfAskPlanner selfAskPlanner;
    private final RelevanceScoringService relevanceScoringService;
    private final HyperparameterService hp; // â˜… NEW: ë™ì  ê°€ì¤‘ì¹˜ ë¡œë”
    private final ElementConstraintScorer elementConstraintScorer; // â˜… NEW: ì›ì†Œ ì œì•½ ì¬ë­ì»¤
    // ğŸ”´ NEW: êµì°¨ì—”ì½”ë” ê¸°ë°˜ ì¬ì •ë ¬(ì—†ìœ¼ë©´ ìŠ¤í‚µ)
    @Autowired(required = false)
    private com.example.lms.service.rag.rerank.CrossEncoderReranker crossEncoderReranker;
    // ë¦¬íŠ¸ë¦¬ë²„ë“¤
    private final SelfAskWebSearchRetriever selfAskRetriever;
    private final AnalyzeWebSearchRetriever analyzeRetriever;
    private final WebSearchRetriever webSearchRetriever;
    private final QueryComplexityGate gate;

    // (ì˜µì…˜) íƒ€ì‚¬ ê²€ìƒ‰ê¸° â€“ ìˆìœ¼ë©´ ë¶€ì¡±ë¶„ ë³´ê°•ì— ì‚¬ìš©
    @Autowired(required = false)
    @org.springframework.beans.factory.annotation.Qualifier("tavilyWebSearchRetriever")
    private ContentRetriever tavilyWebSearchRetriever;
    // RAG/ì„ë² ë”©
    private final LangChainRAGService ragService;
    private final EmbeddingModel embeddingModel;
    private final EmbeddingStore<TextSegment> gameEmbeddingStore;

    @Value("${pinecone.index.name}")
    private String pineconeIndexName;

    @Value("${hybrid.debug.sequential:false}")
    private boolean debugSequential;
    @Value("${hybrid.progressive.quality-min-docs:4}")
    private int qualityMinDocs;
    @Value("${hybrid.progressive.quality-min-score:0.62}")
    private double qualityMinScore;
    @Value("${hybrid.max-parallel:3}")
    private int maxParallel;

    @Value("${hybrid.min-relatedness:0.4}")  //  ê´€ë ¨ë„ í•„í„° ì»·ì˜¤í”„
    private double minRelatedness;
    // â˜… ìœµí•© ëª¨ë“œ: rrf(ê¸°ë³¸) | softmax
    @Value("${retrieval.fusion.mode:rrf}")
    private String fusionMode;
    // â˜… softmax ìœµí•© ì˜¨ë„
    @Value("${retrieval.fusion.softmax.temperature:1.0}")
    private double fusionTemperature;
    @Value("${retrieval.rank.use-ml-correction:true}")
    private boolean useMlCorrection;  // â˜… NEW: ML ë³´ì • ì˜¨/ì˜¤í”„

    @Override
    public List<Content> retrieve(Query query) {

        // 0) ë©”íƒ€ íŒŒì‹±
        String sessionKey = Optional.ofNullable(query)
                .map(Query::metadata)
                .map(HybridRetriever::toMap)
                .map(md -> md.get(LangChainRAGService.META_SID))
                .map(Object::toString)
                .orElse(null);

        Map<String, Object> md = Optional.ofNullable(query)
                .map(Query::metadata)
                .map(HybridRetriever::toMap)
                .orElse(Map.of());

        @SuppressWarnings("unchecked")
        List<String> allowedDomains =
                (List<String>) md.getOrDefault(META_ALLOWED_DOMAINS, List.of());
        @SuppressWarnings("unchecked")
        List<String> officialDomains =
                (List<String>) md.getOrDefault(META_OFFICIAL_DOMAINS, allowedDomains);

        // ë©”íƒ€ì— ë“¤ì–´ì˜¨ ë³‘ë ¬ ìƒí•œ(ì—†ìœ¼ë©´ ê¸°ë³¸ì„¤ì • ì‚¬ìš©)
        int maxParallelOverride = Optional.ofNullable((Integer) md.get(META_MAX_PARALLEL)).orElse(this.maxParallel);
        String dedupeKey = (String) md.getOrDefault(META_DEDUPE_KEY, "text");

        LinkedHashSet<Content> mergedContents = new LinkedHashSet<>();

        // 1) ë‚œì´ë„ ê²Œì´íŒ…
        final String q = (query != null && query.text() != null) ? query.text().strip() : "";
        QueryComplexityGate.Level level = gate.assess(q);
        log.debug("[Hybrid] level={} q='{}'", level, q);

        switch (level) {
            case SIMPLE -> {
                // ì›¹ ìš°ì„ , ë¶€ì¡±í•˜ë©´ ë²¡í„°
                mergedContents.addAll(webSearchRetriever.retrieve(query));
                if (mergedContents.size() < topK) {
                    ContentRetriever pine = ragService.asContentRetriever(pineconeIndexName);
                    mergedContents.addAll(pine.retrieve(query));
                }
                if (mergedContents.size() < topK && tavilyWebSearchRetriever != null) {
                    try { mergedContents.addAll(tavilyWebSearchRetriever.retrieve(query)); }
                    catch (Exception e) { log.debug("[Hybrid] Tavily fallback skipped: {}", e.toString()); }
                }
            }
            case AMBIGUOUS -> {
                mergedContents.addAll(analyzeRetriever.retrieve(query));
                if (mergedContents.size() < topK) mergedContents.addAll(webSearchRetriever.retrieve(query));
                if (mergedContents.size() < topK) {
                    ContentRetriever pine = ragService.asContentRetriever(pineconeIndexName);
                    mergedContents.addAll(pine.retrieve(query));
                }
                if (mergedContents.size() < topK && tavilyWebSearchRetriever != null) {
                    try { mergedContents.addAll(tavilyWebSearchRetriever.retrieve(query)); }
                    catch (Exception e) { log.debug("[Hybrid] Tavily fallback skipped: {}", e.toString()); }
                }
            }
            case COMPLEX -> {
                mergedContents.addAll(selfAskRetriever.retrieve(query));
                if (mergedContents.size() < topK) mergedContents.addAll(analyzeRetriever.retrieve(query));
                if (mergedContents.size() < topK) mergedContents.addAll(webSearchRetriever.retrieve(query));
                if (mergedContents.size() < topK) {
                    ContentRetriever pine = ragService.asContentRetriever(pineconeIndexName);
                    mergedContents.addAll(pine.retrieve(query));
                }
                if (mergedContents.size() < topK && tavilyWebSearchRetriever != null) {
                    try { mergedContents.addAll(tavilyWebSearchRetriever.retrieve(query)); }
                    catch (Exception e) { log.debug("[Hybrid] Tavily fallback skipped: {}", e.toString()); }
                }

            }
        }

        // ìµœì¢… ì •ì œ í›„ ë°˜í™˜
        return finalizeResults(new ArrayList<>(mergedContents), dedupeKey, officialDomains, q);
    }

    /**
     * Progressive retrieval:
     * 1) Local RAG ìš°ì„  â†’ í’ˆì§ˆ ì¶©ë¶„ ì‹œ ì¡°ê¸° ì¢…ë£Œ
     * 2) ë¯¸í¡ ì‹œ Self-Ask(1~2ê°œ)ë¡œ ì •ì œëœ ì›¹ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
     */
    @Deprecated // â† í­í¬ìˆ˜ ê²€ìƒ‰ ë¹„í™œì„±í™” ê²½ë¡œ(ë‚¨ê²¨ë‘ë˜ í˜¸ì¶œì€ ë‚¨ê¹€)
    public List<Content> retrieveProgressive(String question, String sessionKey, int limit) {
        if (question == null || question.isBlank()) {
            return List.of(Content.from("[ë¹ˆ ì§ˆì˜]"));
        }
        final int top = Math.max(1, limit);

        try {
            // 1) ë¡œì»¬ RAG ìš°ì„ 
            ContentRetriever pine = ragService.asContentRetriever(pineconeIndexName);
            List<Content> local = pine.retrieve(Query.from(question));

            if (qualityEvaluator != null && qualityEvaluator.isSufficient(question, local, qualityMinDocs, qualityMinScore)) {
                log.info("[Hybrid] Local RAG sufficient â†’ skip web (sid={}, q='{}')", sessionKey, question);
                List<Content> out = finalizeResults(new ArrayList<>(local), "text", java.util.Collections.emptyList(), question);
                return out.size() > top ? out.subList(0, top) : out;
            }

            // 2) Selfâ€‘Askë¡œ 1~2ê°œ í•µì‹¬ ì§ˆì˜ ìƒì„± â†’ ìœ„ìƒ í•„í„°
            List<String> planned = (selfAskPlanner != null) ? selfAskPlanner.plan(question, 2) : List.of(question);
            List<String> queries = QueryHygieneFilter.sanitize(planned, 2, 0.80);

            if (queries.isEmpty()) queries = List.of(question);

            // 3) í•„ìš”í•œ ì¿¼ë¦¬ë§Œ ìˆœì°¨ ì²˜ë¦¬ â†’ ìœµí•©
            List<List<Content>> buckets = new ArrayList<>();
            for (String q : queries) {
                List<Content> acc = new ArrayList<>();
                try {
                    handlerChain.handle(Query.from(q), acc);
                } catch (Exception e) {
                    log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", e.toString());
                }
                buckets.add(acc);
            }


            // ìœµí•© ë° ìµœì¢… ì •ì œ í›„ ìƒìœ„ top ë°˜í™˜
            List<Content> fused = "softmax".equalsIgnoreCase(fusionMode)
                    ? fuseWithSoftmax(buckets, top, question) // â˜… ëŒ€ì•ˆ ìœµí•©
                    : fuser.fuse(buckets, top);               // ê¸°ë³¸ RRF
            List<Content> combined = new ArrayList<>(local); // 'local'ì€ ì´ ë©”ì†Œë“œ ìƒë‹¨ì—ì„œ ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
            combined.addAll(fused);

            List<Content> out = finalizeResults(combined, "text", java.util.Collections.emptyList(), question);
            return out.size() > top ? out.subList(0, top) : out;

        } catch (Exception e) {
            log.error("[Hybrid] retrieveProgressive ì‹¤íŒ¨(sid={}, q='{}')", sessionKey, question, e);
            return List.of(Content.from("[ê²€ìƒ‰ ì˜¤ë¥˜]"));
        }
    }


/**
 * ë‹¤ì¤‘ ì¿¼ë¦¬ ë³‘ë ¬ ê²€ìƒ‰  RRF ìœµí•©
 */

    /**
     * ë‹¤ì¤‘ ì¿¼ë¦¬ ë³‘ë ¬ ê²€ìƒ‰ + RRF ìœµí•©
     */
    public List<Content> retrieveAll(List<String> queries, int limit) {
        if (queries == null || queries.isEmpty()) {
            return List.of(Content.from("[ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ]"));
        }

        try {
            List<List<Content>> results;
            if (debugSequential) {
                log.warn("[Hybrid] debug.sequential=true â†’ handlerChain ìˆœì°¨ ì‹¤í–‰");
                results = new ArrayList<>();
                for (String q : queries) {
                    List<Content> acc = new ArrayList<>();
                    try {
                        handlerChain.handle(Query.from(q), acc);
                    } catch (Exception e) {
                        log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", q, e);
                    }
                    results.add(acc);
                }
            } else {
                // ê¸°ë³¸: ì œí•œ ë³‘ë ¬ ì‹¤í–‰ (ê³µìš© í’€ ì‚¬ìš© ê¸ˆì§€)
                ForkJoinPool pool = new ForkJoinPool(Math.max(1, this.maxParallel));
                try {
                    results = pool.submit(() ->
                            queries.parallelStream()
                                    .map(q -> {
                                        List<Content> acc = new ArrayList<>();
                                        try {
                                            handlerChain.handle(Query.from(q), acc);
                                        } catch (Exception e) {
                                            log.warn("[Hybrid] handler ì‹¤íŒ¨: {}", q, e);
                                        }
                                        return acc;
                                    })
                                    .toList()
                    ).join();
                } finally {
                    pool.shutdown();
                }
            }
            // RRF or Softmax ìœµí•© í›„ ìƒìœ„ limit ë°˜í™˜
            if ("softmax".equalsIgnoreCase(fusionMode)) {
                String q0 = queries.get(0); // ëŒ€í‘œ ì§ˆì˜(ê°„ë‹¨ ê·¼ì‚¬)
                return fuseWithSoftmax(results, Math.max(1, limit), q0);
            }
            return fuser.fuse(results, Math.max(1, limit));
        } catch (Exception e) { // retrieveAll ì¢…ë£Œ
            log.error("[Hybrid] retrieveAll ì‹¤íŒ¨", e);
            return List.of(Content.from("[ê²€ìƒ‰ ì˜¤ë¥˜]"));
        }
        // í´ë˜ìŠ¤ ì¢…ë£ŒëŠ” íŒŒì¼ ë§ë¯¸ë¡œ ì´ë™ (í—¬í¼ ë©”ì„œë“œ í¬í•¨)

    } // retrieveAll ë

    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * (ì˜µì…˜) ì½”ì‚¬ì¸ ìœ ì‚¬ë„ â€” í•„ìš” ì‹œ ì‚¬ìš©
     */
    private double cosineSimilarity(String q, String doc) {
        try {
            var qVec = embeddingModel.embed(q).content().vector();
            var dVec = embeddingModel.embed(doc).content().vector();
            if (qVec.length != dVec.length) {
                throw new IllegalArgumentException("Embedding dimension mismatch");
            }
            double dot = 0, nq = 0, nd = 0;
            for (int i = 0; i < qVec.length; i++) {
                dot += qVec[i] * dVec[i];
                nq += qVec[i] * qVec[i];
                nd += dVec[i] * dVec[i];
            }
            if (nq == 0 || nd == 0) return 0d;
            return dot / (Math.sqrt(nq) * Math.sqrt(nd) + 1e-9);
        } catch (Exception e) {
            return 0d;
        }
    }

    @SuppressWarnings("unchecked")
    private static Map<String, Object> toMap(Object meta) {
        if (meta == null) return Map.of();
        try {
            Method m = meta.getClass().getMethod("asMap");
            return (Map<String, Object>) m.invoke(meta);
        } catch (NoSuchMethodException e) {
            try {
                Method m = meta.getClass().getMethod("map");
                return (Map<String, Object>) m.invoke(meta);
            } catch (Exception ex) {
                return Map.of();
            }
        } catch (Exception ex) {
            return Map.of();
        }
    }

    private static String extractUrl(String text) {
        if (text == null) return null;
        int a = text.indexOf("href=\"");
        if (a >= 0) {
            int s = a + 6, e = text.indexOf('"', s);
            if (e > s) return text.substring(s, e);
        }
        int http = text.indexOf("http");
        if (http >= 0) {
            int sp = text.indexOf(' ', http);
            return sp > http ? text.substring(http, sp) : text.substring(http);
        }
        return null;
    }

    private static boolean isOfficial(String url, List<String> officialDomains) {
        if (url == null || officialDomains == null) return false;
        for (String d : officialDomains) {
            if (d != null && !d.isBlank() && url.contains(d.trim())) return true;
        }
        return false;
    }

    /**
     * ìµœì¢… ì •ì œ:
     * - dedupeKey ê¸°ì¤€ ì¤‘ë³µ ì œê±°
     * - ê³µì‹ ë„ë©”ì¸ ë³´ë„ˆìŠ¤(+0.20)
     * - ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ topK ë°˜í™˜
     */
    private List<Content> finalizeResults(List<Content> raw,
                                          String dedupeKey,
                                          List<String> officialDomains,
                                          String queryText) {

        // 1) ì¤‘ë³µ ì œê±° + ì €ê´€ë ¨ í•„í„°
        Map<String, Content> uniq = new LinkedHashMap<>();
        for (Content c : raw) {
            if (c == null) continue;

            String text = Optional.ofNullable(c.textSegment())
                    .map(TextSegment::text)
                    .orElse(c.toString());

            double rel = 0.0;
            try {
                rel = relevanceScoringService.relatedness(
                        Optional.ofNullable(queryText).orElse(""),
                        text
                );
            } catch (Exception ignore) { }
            if (rel < minRelatedness) continue;

            String key;
            switch (dedupeKey) {
                case "url" -> key = Optional.ofNullable(extractUrl(text)).orElse(text);
                case "hash" -> key = Integer.toHexString(text.hashCode());
                default -> key = text; // "text"
            }
            uniq.putIfAbsent(key, c);
        }

        // 2) ê²½ëŸ‰ 1ì°¨ ë­í‚¹ (ì—†ìœ¼ë©´ candidates ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        List<Content> candidates = new ArrayList<>(uniq.values());
        List<Content> firstPass = (lightWeightRanker != null)
                ? lightWeightRanker.rank(
                candidates,
                Optional.ofNullable(queryText).orElse(""),
                Math.max(topK * 2, 20)
        )
                : candidates;

        //  ì›ì†Œ ì œì•½ ê¸°ë°˜ ë³´ì •(ì¶”ì²œ ì˜ë„Â·ì œì•½ì€ ì „ì²˜ë¦¬ê¸°ì—ì„œ ìœ ë„)
        if (elementConstraintScorer != null) {
            try {
                firstPass = elementConstraintScorer.rescore(
                        Optional.ofNullable(queryText).orElse(""),
                        firstPass
                );
            } catch (Exception ignore) { /* ì•ˆì „ ë¬´ì‹œ */ }
        }

        // 2â€‘B) ğŸ”´ (ì˜µì…˜) êµì°¨ì—”ì½”ë” ì¬ì •ë ¬: ì§ˆë¬¸ê³¼ì˜ ì˜ë¯¸ ìœ ì‚¬ë„ ì •ë°€ ì¬ê³„ì‚°
        if (crossEncoderReranker != null && !candidates.isEmpty()) {
            try {
                candidates = crossEncoderReranker.rerank(
                        Optional.ofNullable(queryText).orElse(""), candidates, Math.max(topK * 2, 20));
            } catch (Exception e) {
                log.debug("[Hybrid] cross-encoder rerank skipped: {}", e.toString());
            }
        }

        // 3) ì •ë°€ ìŠ¤ì½”ì–´ë§ + ì •ë ¬
        class Scored {
            final Content content;
            final double score;
            Scored(Content content, double score) { this.content = content; this.score = score; }
        }
        List<Scored> scored = new ArrayList<>();
        int rank = 0;
        // â˜… NEW: ë™ì  ë­í‚¹ ê°€ì¤‘ì¹˜/ë³´ë„ˆìŠ¤
        final double wRel  = hp.getDouble("retrieval.rank.w.rel",  0.60);
        final double wBase = hp.getDouble("retrieval.rank.w.base", 0.30);
        final double wAuth = hp.getDouble("retrieval.rank.w.auth", 0.10);
        final double bonusOfficial = hp.getDouble("retrieval.rank.bonus.official", 0.20);

        // â˜… NEW: ML ë³´ì • ê³„ìˆ˜
        final double alpha  = hp.getDouble("ml.correction.alpha",  0.0);
        final double beta   = hp.getDouble("ml.correction.beta",   0.0);
        final double gamma  = hp.getDouble("ml.correction.gamma",  0.0);
        final double d0     = hp.getDouble("ml.correction.d0",     0.0);
        final double mu     = hp.getDouble("ml.correction.mu",     0.0);
        final double lambda = hp.getDouble("ml.correction.lambda", 1.0);

        for (Content c : firstPass) {
            rank++;
            double base = 1.0 / rank;

            String text = Optional.ofNullable(c.textSegment())
                    .map(TextSegment::text)
                    .orElse(c.toString());

            String url = extractUrl(text);

            double authority = authorityScorer != null ? authorityScorer.weightFor(url) : 0.5;

            double rel = 0.0;
            try {
                rel = relevanceScoringService.relatedness(
                        Optional.ofNullable(queryText).orElse(""),
                        text
                );
            } catch (Exception ignore) { }

            // â˜… NEW: ìµœì¢… ì ìˆ˜ = wRel*ê´€ë ¨ë„ + wBase*ê¸°ë³¸ë­í¬ + wAuth*Authority (+ê³µì‹ë„ë©”ì¸ ë³´ë„ˆìŠ¤)
            double score0 = (wRel * rel) + (wBase * base) + (wAuth * authority);
            if (isOfficial(url, officialDomains)) {
                score0 += bonusOfficial;
            }
// â˜… NEW: ML ë¹„ì„ í˜• ë³´ì •(ì˜µì…˜) â€“ ê°’åŸŸ ë³´ì • ë° tail ì œì–´
            double finalScore = useMlCorrection
                    ? MLCalibrationUtil.finalCorrection(score0, alpha, beta, gamma, d0, mu, lambda, true)
                    : score0;
            scored.add(new Scored(c, finalScore));
        }

        scored.sort((a, b) -> Double.compare(b.score, a.score));
        return scored.stream()
                .limit(topK)
                .map(s -> s.content)
                .collect(Collectors.toList());
    }
    // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NEW: Softmax ìœµí•©(ë‹¨ì¼ ì •ì˜ë§Œ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    /** ì—¬ëŸ¬ ë²„í‚·ì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ ëª¨ì•„ ì ìˆ˜(logit)ë¥¼ ë§Œë“¤ê³  softmaxë¡œ ì •ê·œí™”í•œ ë’¤ ìƒìœ„ Nì„ ê³ ë¥¸ë‹¤. */
    private List<Content> fuseWithSoftmax(List<List<Content>> buckets, int limit, String queryText) {
        Map<String, Content> keeper = new LinkedHashMap<>();
        Map<String, Double>  logit  = new LinkedHashMap<>();

        int bIdx = 0;
        for (List<Content> bucket : buckets) {
            if (bucket == null) continue;
            int rank = 0;
            for (Content c : bucket) {
                rank++;
                String text = Optional.ofNullable(c.textSegment()).map(TextSegment::text).orElse(c.toString());
                String key  = Integer.toHexString(text.hashCode()); // ê°„ë‹¨ dedupe
                String url  = extractUrl(text);
                double authority = (authorityScorer != null) ? authorityScorer.weightFor(url) : 0.5;
                double related   = 0.0;
                try { related = relevanceScoringService.relatedness(Optional.ofNullable(queryText).orElse(""), text); } catch (Exception ignore) {}
                double base      = 1.0 / (rank + 0.0);           // ìƒìœ„ ë­í¬ ê°€ì¤‘
                double bucketW   = 1.0 / (bIdx + 1.0);           // ì•ì„  ë²„í‚· ì•½ê°„ ìš°ëŒ€
                double l = (0.6 * related) + (0.1 * authority) + (0.3 * base * bucketW);

                keeper.putIfAbsent(key, c);
                logit.merge(key, l, Math::max); // ê°™ì€ ë¬¸ì„œëŠ” ê°€ì¥ ë†’ì€ logitë§Œ ìœ ì§€
            }
            bIdx++;
        }
        if (logit.isEmpty()) return List.of();

        // softmax ì •ê·œí™”(ìˆ˜ì¹˜ ì•ˆì •í™” í¬í•¨) í›„ í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        String[] keys = logit.keySet().toArray(new String[0]);
        double[] arr  = logit.values().stream().mapToDouble(d -> d).toArray();
        double[] p    = SoftmaxUtil.softmax(arr, fusionTemperature);

        // í™•ë¥  ë‚´ë¦¼ì°¨ìˆœ ìƒìœ„ limit
        java.util.List<Integer> idx = new java.util.ArrayList<>();
        for (int i = 0; i < p.length; i++) idx.add(i);
        idx.sort((i, j) -> Double.compare(p[j], p[i]));

        java.util.List<Content> out = new java.util.ArrayList<>();
        for (int i = 0; i < Math.min(limit, idx.size()); i++) {
            out.add(keeper.get(keys[idx.get(i)]));
        }
        return out;
    }


}